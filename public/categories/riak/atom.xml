<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Riak | OJ's rants]]></title>
  <link href="http://buffered.io/categories/riak/atom.xml" rel="self"/>
  <link href="http://buffered.io/"/>
  <updated>2012-05-03T17:01:50+10:00</updated>
  <id>http://buffered.io/</id>
  <author>
    <name><![CDATA[OJ Reeves]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Webmachine, ErlyDTL and Riak - Part 4]]></title>
    <link href="http://buffered.io/posts/webmachine-erlydtl-and-riak-part-4/"/>
    <updated>2012-02-15T20:50:00+10:00</updated>
    <id>http://buffered.io/posts/webmachine-erlydtl-and-riak-part-4</id>
    <content type="html"><![CDATA[<p>{% img left /uploads/2010/09/riak-logo.png 'Riak Logo' %}For those of you who are new to the series, you may want to check out <a href="/posts/webmachine-erlydtl-and-riak-part-1/" title="Wembachine, ErlyDTL and Riak - Part 1">Part 1</a>, <a href="/posts/webmachine-erlydtl-and-riak-part-2/" title="Wembachine, ErlyDTL and Riak - Part 2">Part 2</a> and <a href="/posts/webmachine-erlydtl-and-riak-part-3/" title="Wembachine, ErlyDTL and Riak - Part 3">Part 3</a> before reading this post. It will help give you some context as well as introduce you to some of the jargon and technology that I'm using. If you've already read then, or don't want to, then please read on!</p>

<p>Upon finishing <a href="/posts/webmachine-erlydtl-and-riak-part-3/" title="Wembachine, ErlyDTL and Riak - Part 3">Part 3</a> of the series we were finally able to read data from <a href="http://www.basho.com/developers.html#Riak" title="Riak">Riak</a> and see it appear in our web page. This was the first stage in seeing a full end-to-end web application functioning. Of course there is still a great deal to do!</p>

<!--more-->


<h2>Agenda</h2>

<p>In this post we're going to hit a few points of pain:</p>

<ol>
<li>Another slight refactor! We need to manage Riak connections in a smarter way, so we'll do that first.</li>
<li>We'll be dealing with more configuration so we'll change the way our application deals with configuration so that it's all in the one spot and a little easier to manage.</li>
<li>Add the ability for users to sign in. To keep this simple and avoid the need for users to manage yet another login, we're going to use <a href="http://oauth.net/" title="OAuth">OAuth</a> and let people sign in with their <a href="http://twitter.com/" title="Twitter">Twitter</a> accounts.</li>
<li>Store a cookie in the user's browser which contains identifying information and an encrypted set of OAuth tokens.</li>
</ol>


<p>There's little Riak-specific work going on this post as we're focusing on front-end user management. Other than a bit of refactoring the Riak code remains the same as in Part 3. In Part 5 (coming soon) we'll be writing snippets to Riak and associating them to users who have logged into the application via Twitter.</p>

<p><strong>NOTE</strong>: I'll no longer be using <code>localhost</code> in URLs and will instead be using the loopback address, <code>127.0.0.1</code>. The main reason is because we'll be interacting with Twitter which requires a "proper" address to be used when setting up. A secondary reason is the use of cookies. If I accidentally leave <code>localhost</code> somewhere in the post (or in the images) please let me know.</p>

<p>Again, be warned, this post is a bit of a whopper! So get yourself a drink and get comfortable. Here we go...</p>

<h2>Another Slight Refactor</h2>

<p>Now that we're at the stage where Riak is going to get used more often we need to do a better job of handling and managing the connections to the cluster. Ideally we should pool a bunch of connections and reuse them across different requests. This reduces the overhead of creating and destroying connections all the time. Initially we're going to make use of Seth's <a href="https://github.com/seth/pooler" title="Pooler">Pooler</a> application (with a slight modification) to handle the pooling of Riak connections for us.</p>

<h3>Fixing HAProxy</h3>

<p>So now that we have a plan to pool connections, the first thing we need to fix is our load-balancer's configuration. At the moment we have configured <a href="http://haproxy.1wt.eu/" title="HAProxy">HAProxy</a> with the following settings:</p>

<p>{% codeblock dev.haproxy.conf lang:bash %}</p>

<h1>now set the default settings for each sub-section</h1>

<p>defaults
  .
  .
  # specify some timeouts (all in milliseconds)
  timeout connect 5000
  timeout client 50000
  timeout server 50000
  .
  .
{% endcodeblock %}</p>

<p>As you can see we've forced the timeout of connections which means that every connection that is made to the proxy will be killed off when it has been inactive for a long enough period of time. If you were paying attention to the output in the application console window you'd have seen something like this appear after making a request:</p>

<pre><code>=ERROR REPORT==== 13-Aug-2011::20:52:01 ===
** Generic server &lt;0.99.0&gt; terminating 
** Last message in was {tcp_closed,#Port&lt;0.2266&gt;}
** When Server state == {state,"127.0.0.1",8080,false,false,undefined,
                               undefined,
                               {[],[]},
                               1,[],infinity,100}
** Reason for termination == 
** disconnected

=CRASH REPORT==== 13-Aug-2011::20:52:01 ===
  crasher:
    initial call: riakc_pb_socket:init/1
    pid: &lt;0.99.0&gt;
    registered_name: []
    exception exit: disconnected
      in function  gen_server:terminate/6
    ancestors: [csd_core_server,csd_core_sup,&lt;0.52.0&gt;]
    messages: []
    links: [&lt;0.54.0&gt;]
    dictionary: []
    trap_exit: false
    status: running
    heap_size: 377
    stack_size: 24
    reductions: 911
  neighbours:
    neighbour: [{pid,&lt;0.54.0&gt;},
                  {registered_name,csd_core_server},
                  {initial_call,{csd_core_server,init,['Argument__1']}},
                  {current_function,{gen_server,loop,6}},
                  {ancestors,[csd_core_sup,&lt;0.52.0&gt;]},
                  {messages,[]},
                  {links,[&lt;0.53.0&gt;,&lt;0.99.0&gt;]},
                  {dictionary,[]},
                  {trap_exit,false},
                  {status,waiting},
                  {heap_size,987},
                  {stack_size,9},
                  {reductions,370}]

=SUPERVISOR REPORT==== 13-Aug-2011::20:52:01 ===
     Supervisor: {local,csd_core_sup}
     Context:    child_terminated
     Reason:     disconnected
     Offender:   [{pid,&lt;0.54.0&gt;},
                  {name,csd_core_server},
                  {mfargs,{csd_core_server,start_link,[]}},
                  {restart_type,permanent},
                  {shutdown,5000},
                  {child_type,worker}]


=PROGRESS REPORT==== 13-Aug-2011::20:52:01 ===
          supervisor: {local,csd_core_sup}
             started: [{pid,&lt;0.104.0&gt;},
                       {name,csd_core_server},
                       {mfargs,{csd_core_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]
</code></pre>

<p>This is paired up with the following output from the HAProxy console:</p>

<pre><code>00000010:riaks.srvcls[0009:000a]
00000010:riaks.clicls[0009:000a]
00000010:riaks.closed[0009:000a]
0000000e:webmachines.srvcls[0006:0007]
0000000e:webmachines.clicls[0006:0007]
0000000e:webmachines.closed[0006:0007]
</code></pre>

<p>These logs from the console clearly indicate that HAProxy is doing exactly what we've told it to do. It's killing off the connections after a period of time.</p>

<p>For a connection pool this is not a good idea. Therefore we need to modify this configuration so that it doesn't kill off connections. Thankfully this is a very simple thing to do! We delete the lines that force <code>client</code> and <code>server</code> timeouts (I'm commenting the lines out to make it obvious which ones you need to remove):</p>

<p>{% codeblock dev.haproxy.conf lang:bash %}</p>

<h1>now set the default settings for each sub-section</h1>

<p>defaults
  .
  .
  # specify some timeouts (all in milliseconds)
  timeout connect 5000
  #timeout client 50000
  #timeout server 50000
  .
  .
{% endcodeblock %}</p>

<p>After making this change to the configuration, HAProxy will no longer kill off the connections. Therefore it's up to us to manage them.</p>

<h3>Connection Pooling</h3>

<p>Given that it is <em>not</em> one of the goals of this series to demonstrate how to create a connection pooling application in Erlang, we're going to use an application that's already out there to do it for us. This application is called <a href="https://github.com/seth/pooler" title="Pooler">Pooler</a>. Out of the box this application does Erlang process pooling, and given that our Riak connections are each Erlang processes, this suits us perfectly.</p>

<p>One thing that I didn't like about the interface to Pooler was that it relied on the caller managing the lifetime of the connection. As a result, I made a small change to the interface in my own <a href="https://github.com/OJ/pooler" title="OJ's Pooler fork">fork</a> which I think helps keep things a little cleaner. This application will be making use of this fork.</p>

<p>First up, we need to add another dependency in our <code>rebar.config</code> file which will pull this application in from Github at a dependency.</p>

<p>{% codeblock apps/csd_core/rebar.config lang:erlang %}
%%-<em>- mode: erlang -</em>-
{deps,
  [</p>

<pre><code>{mochiweb, ".*", {git, "git://github.com/mochi/mochiweb", "HEAD"}},
{riakc, ".*", {git, "git://github.com/basho/riak-erlang-client", "HEAD"}},
{pooler, ".*", {git, "git://github.com/OJ/pooler", "HEAD"}}
</code></pre>

<p>  ]
}.
{% endcodeblock %}</p>

<p>Build the application so that the dependency is pulled and built:</p>

<p>{% codeblock lang:bash %}
oj@hitchens ~/code/csd $ make</p>

<p>   ... snip ...</p>

<p>Pulling pooler from {git,"git://github.com/OJ/pooler","HEAD"}
Cloning into pooler...
==> pooler (get-deps)</p>

<p>   ... snip ...</p>

<p>==> pooler (compile)
Compiled src/pooler_app.erl
Compiled src/pooler_pooled_worker_sup.erl
Compiled src/pooler_pool_sup.erl
Compiled src/pooler_sup.erl
Compiled src/pooler.erl</p>

<p>   ... snip ...
{% endcodeblock %}</p>

<p>Next we need to take the scalpel to <code>csd_core</code>. When we first created this application, it was intended to manage all of the interaction with Riak and to manage the intricacies of dealing with snippets and other objects without exposing Riak's inner workings to the <code>csd_web</code> application. To do this we put a <a href="http://www.erlang.org/doc/man/gen_server.html" title="gen_server">gen_server</a> in place, called <code>csd_core_server</code>, which handled the incoming requests. It internally established connections to Riak and used them without destroying them.</p>

<p>For now, we'll be keeping this <code>gen_server</code> in place but we're going to make some modifications to it:</p>

<ol>
<li>We'll start and stop <code>pooler</code> when our <code>csd_core</code> application starts and stops.</li>
<li>We'll change the way configuration is managed and add the configuration for <code>pooler</code>.</li>
<li>We'll be removing the code that establishes the connections.</li>
<li>We'll pass the calls through to Riak using the new <code>pooler</code> application.</li>
</ol>


<p>Let's get to it.</p>

<h4>Starting and Stopping Pooler</h4>

<p>Given that we're using <code>pooler</code> the first thing we need to do is make sure that it loads and runs when <code>csd_core</code> fires up. To do this, we need to modify <code>csd_core.erl</code> so that it looks like this:</p>

<p>{% codeblock apps/csd_core/src/csd_core.erl lang:erlang %}
%% @author OJ Reeves <a href="&#109;&#97;&#105;&#108;&#x74;&#x6f;&#58;&#x6f;&#x6a;&#x40;&#98;&#x75;&#x66;&#x66;&#x65;&#x72;&#x65;&#100;&#x2e;&#x69;&#x6f;">&#x6f;&#106;&#x40;&#98;&#117;&#102;&#102;&#x65;&#114;&#101;&#x64;&#46;&#x69;&#111;</a>
%% @copyright 2011 OJ Reeves</p>

<p>%% @doc csd_core startup code</p>

<p>-module(csd_core).
-author('OJ Reeves <a href="&#x6d;&#97;&#105;&#x6c;&#x74;&#111;&#x3a;&#111;&#x6a;&#64;&#x62;&#x75;&#102;&#102;&#101;&#x72;&#x65;&#x64;&#x2e;&#x69;&#111;">&#111;&#x6a;&#64;&#x62;&#x75;&#x66;&#x66;&#x65;&#114;&#x65;&#x64;&#46;&#x69;&#111;</a>').
-export([start/0, start_link/0, stop/0]).</p>

<p>ensure_started(App) -></p>

<pre><code>case application:start(App) of
    ok -&gt;
        ok;
    {error, {already_started, App}} -&gt;
        ok
end.
</code></pre>

<p>%% @spec start_link() -> {ok,Pid::pid()}
%% @doc Starts the app for inclusion in a supervisor tree
start_link() -></p>

<pre><code>start_common(),
csd_core_sup:start_link().
</code></pre>

<p>%% @spec start() -> ok
%% @doc Start the csd_core server.
start() -></p>

<pre><code>start_common(),
application:start(csd_core).
</code></pre>

<p>%% @spec stop() -> ok
%% @doc Stop the csd_core server.
stop() -></p>

<pre><code>Res = application:stop(csd_core),
application:stop(pooler),
application:stop(crypto),
Res.
</code></pre>

<p>%% @private
start_common() -></p>

<pre><code>ensure_started(crypto),
ensure_started(pooler).
</code></pre>

<p>{% endcodeblock %}</p>

<p>This code will start and stop the <code>pooler</code> application along with our application. Exactly what we need!</p>

<h4>Fixing Configuration</h4>

<p>Our rudimentary configuration module, <code>csd_riak_config.erl</code>, is now obsolete. We're going to remove it and replace it with something a little more complicated which will not only make it easier to handle configuration using Erlang's built-in <a href="http://www.erlang.org/doc/man/config.html" title="Erlang configuration">configuration</a> handling, but we'll add some code which will make it easier to access configuration both in development <em>and</em> once the application has been deployed.</p>

<p>Let's start by creating a new file:</p>

<p>{% codeblock apps/csd_core/priv/app.config lang:erlang %}
[
  {pooler, [</p>

<pre><code>  {pools, [
      [
        {name, "haproxy"},
        {max_count, 30},
        {init_count, 5},
        {start_mfa, {riakc_pb_socket, start_link, ["127.0.0.1", 8080]}}
      ]
    ]}
]}
</code></pre>

<p>].
{% endcodeblock %}</p>

<p><code>pooler</code> is smart enough to pool connections across multiple nodes. This is quite a nifty feature, but not one that we're making use of because we have HAProxy in place. Therefore, the configuration above is telling Pooler to use just one single node/pool (ie. the proxy), to create 5 connections and to allow up to 30 to be created if required.</p>

<p>The last parameter in the configuration, <code>start_mfa</code>, tells <code>pooler</code> which module, function and arguments to invoke to create the Erlang process from. In our case we want it to create a pool of Riak client connections, hence why we've specified the <code>start_link</code> function in the <code>riakc_pb_socket</code> module.</p>

<p>Next we modify our <code>Makefile</code> so that when we invoke <code>make webstart</code> the configuration is properly included:</p>

<p>{% codeblock Makefile lang:bash %}
.PHONY: deps</p>

<p>REBAR=<code>which rebar || ./rebar</code></p>

<p>all: deps compile</p>

<p>compile:</p>

<pre><code>@$(REBAR) compile
</code></pre>

<p>app:</p>

<pre><code>@$(REBAR) compile skip_deps=true
</code></pre>

<p>deps:</p>

<pre><code>@$(REBAR) get-deps
</code></pre>

<p>clean:</p>

<pre><code>@$(REBAR) clean
</code></pre>

<p>distclean: clean</p>

<pre><code>@$(REBAR) delete-deps
</code></pre>

<p>test: app</p>

<pre><code>@$(REBAR) eunit skip_deps=true
</code></pre>

<p>webstart: app</p>

<pre><code>exec erl -pa $(PWD)/apps/*/ebin -pa $(PWD)/deps/*/ebin -boot start_sasl -config $(PWD)/apps/csd_core/priv/app.config -s reloader -s csd_core -s csd_web
</code></pre>

<p>proxystart:</p>

<pre><code>@haproxy -f dev.haproxy.conf
</code></pre>

<p>{% endcodeblock %}</p>

<p>At this point we are able to build and run the application just as we were before. The first thing you'll notice is that the HAProxy console immediately registers 5 new connections:</p>

<p>{% codeblock lang:bash %}
0000004:dbcluster.accept(0005)=0006 from [127.0.0.1:34536]
00000005:dbcluster.accept(0005)=0008 from [127.0.0.1:58770]
00000006:dbcluster.accept(0005)=000a from [127.0.0.1:44734]
00000007:dbcluster.accept(0005)=000c from [127.0.0.1:33874]
00000008:dbcluster.accept(0005)=000e from [127.0.0.1:35815]
{% endcodeblock %}</p>

<p>This is evidence that <code>pooler</code> is doing its job and starting with 5 connections. Now that we have this in place, let's get rid of the old configuration:</p>

<p>{% codeblock lang:bash %}
oj@hitchens ~/code/csd $ rm apps/csd_core/src/csd_riak_config.erl
{% endcodeblock %}</p>

<p>That was easy! We now need to remove any references to this module, thankfully the only module that used was <code>csd_core_server.erl</code>, and that's the one we're going to fix up now. After removing references to the configuration, removing connection creation and replacing it with calls to <code>pooler</code>, <code>csd_core_server</code> now looks like this:</p>

<p>{% codeblock apps/csd_core/src/csd_core_server.erl lang:erlang %}
-module(csd_core_server).
-behaviour(gen_server).
-define(SERVER, ?MODULE).</p>

<p>%% ------------------------------------------------------------------
%% API Function Exports
%% ------------------------------------------------------------------</p>

<p>-export([start_link/0, get_snippet/1, save_snippet/1]).</p>

<p>%% ------------------------------------------------------------------
%% gen_server Function Exports
%% ------------------------------------------------------------------</p>

<p>-export([init/1, handle_call/3, handle_cast/2, handle_info/2, terminate/2, code_change/3]).</p>

<p>%% ------------------------------------------------------------------
%% API Function Definitions
%% ------------------------------------------------------------------</p>

<p>start_link() ->
  gen_server:start_link({local, ?SERVER}, ?MODULE, [], []).</p>

<p>save_snippet(Snippet) ->
  gen_server:call(?SERVER, {save_snippet, Snippet}, infinity).</p>

<p>get_snippet(SnippetKey) ->
  gen_server:call(?SERVER, {get_snippet, SnippetKey}, infinity).</p>

<p>%% ------------------------------------------------------------------
%% gen_server Function Definitions
%% ------------------------------------------------------------------</p>

<p>init([]) ->
  {ok, undefined}.</p>

<p>handle_call({save_snippet, Snippet}, _From, State) ->
  SavedSnippet = pooler:use_member(fun(RiakPid) -> csd_snippet:save(RiakPid, Snippet) end),
  {reply, SavedSnippet, State};</p>

<p>handle_call({get_snippet, SnippetKey}, _From, State) ->
  Snippet = pooler:use_member(fun(RiakPid) -> csd_snippet:fetch(RiakPid, SnippetKey) end),
  {reply, Snippet, State};</p>

<p>handle_call(<em>Request, </em>From, State) ->
  {noreply, ok, State}.</p>

<p>handle_cast(_Msg, State) ->
  {noreply, State}.</p>

<p>handle_info(_Info, State) ->
  {noreply, State}.</p>

<p>terminate(<em>Reason, </em>State) ->
  ok.</p>

<p>code_change(<em>OldVsn, State, </em>Extra) ->
  {ok, State}.
{% endcodeblock %}</p>

<p>Here you can see we're making use of the <a href="https://github.com/OJ/pooler/blob/master/src/pooler.erl#L125" title="use_member">pooler:use_member</a> function to easily wrap up the management of the connection's usage lifetime. All traces of the old configuration are gone. We can now rebuild the application using <code>make</code>, fire it up using <code>make webstart</code> and hit the <a href="http://127.0.0.1/snippet/B41kUQ==">same page</a> as before resulting in the same content appearing on screen.</p>

<p>We have now successfully removed the old configuration and connection handling code, and we've replaced it with <code>pooler</code> to handle a pool of connections to the Riak proxy. The last part of our refactor is around configuration for the front-end web application.</p>

<h2>Rewiring Configuration</h2>

<p>Our configuration is going to get more complicated, so to make sure that we're able to better handle and manage it we're going to set up a similar structure to what we had set up in the <code>csd_core</code> application (in the previous section). The first thing we're going to change is the way that the <strong>Webmachine</strong> routes are loaded. Right now, they're stored in <code>apps/tr_web/priv/dispatch.conf</code>. This configuration belongs alongside others, so we'll move that to an <code>app.config</code> file and re-jig the code to load it from there.</p>

<p>First up, rename the file:</p>

<pre><code>oj@air ~/code/csd/apps/csd_web/priv $ mv dispatch.conf app.config
</code></pre>

<p>Now let's edit it so that it takes the appropriate format:</p>

<p>{% codeblock apps/csd_web/priv/app.config lang:erlang %}
%%-<em>- mode: erlang -</em>-
[
  {sasl,</p>

<pre><code>[
  {sasl_error_logger, {file, "log/sasl-error.log"}},
  {errlog_type, error},
  {error_logger_mf_dir, "log/sasl"},      % Log directory
  {error_logger_mf_maxbytes, 10485760},   % 10 MB max file size
  {error_logger_mf_maxfiles, 5}           % 5 files max
]
</code></pre>

<p>  },
  {csd_web,</p>

<pre><code>[
  {web,
    [
      {ip, "0.0.0.0"},
      {port, 8000},
      {log_dir, "priv/log"},
      {dispatch,
        [
          {[], csd_web_resource, []},
          {["snippet", key], csd_web_snippet_resource, []}
        ]
      }
    ]
  }
]
</code></pre>

<p>  }
].
{% endcodeblock %}</p>

<p>A few things to note here:</p>

<ol>
<li>I've included the <code>sasl</code> configuration for later tweaking.</li>
<li>the <code>csd_web</code> section is named that way so that it is matches the application name. This makes the auto-wiring work.</li>
<li>The Webmachine configuration for application is now in a subsection called <code>web</code>. Inside this section is the original <code>dispatch</code> that we had in our old <code>dispatch.conf</code>. This configuration sections takes the <em>exact</em> form that Webmachine expects when we start its process in our supervisor.</li>
</ol>


<p>At this point we need to go and fiddle with the way Webmachine loads its configuration so that it picks up these details. We'll start by defining a helper which will make it easy to get access to configuration for the <code>csd_web</code> application.</p>

<p>{% codeblock apps/csd_web/src/conf.erl lang:erlang %}
-module(conf).</p>

<p>-export([get_section/1, get_section/2]).
-export([get_val/2, get_val/3]).</p>

<p>get_section(Name) ->
  get_section(Name, undefined).</p>

<p>get_section(Name, Default) ->
  case application:get_env(csd_web, Name) of</p>

<pre><code>{ok, V} -&gt;
  V;
_ -&gt;
  Default
</code></pre>

<p>  end.</p>

<p>get_val(SectionName, Name) ->
  get_val(SectionName, Name, undefined).</p>

<p>get_val(SectionName, Name, Default) ->
  case application:get_env(csd_web, SectionName) of</p>

<pre><code>{ok, Section} -&gt;
  proplists:get_value(Name, Section, Default);
_ -&gt;
  Default
</code></pre>

<p>  end.
{% endcodeblock %}</p>

<p>Configuration helpers are now in place, let's fix the Webmachine loader in <code>csd_web_sup.erl</code>.</p>

<p>{% codeblock apps/csd_web/src/csd_web_sup.erl (partial) lang:erlang %}
% ... snip ... %
%% @spec init([]) -> SupervisorTree
%% @doc supervisor callback.
init([]) ->
  WebConfig = conf:get_section(web),
  Web = {webmachine_mochiweb,</p>

<pre><code>{webmachine_mochiweb, start, [WebConfig]},
permanent, 5000, worker, dynamic},
</code></pre>

<p>  Processes = [Web],
  {ok, { {one_for_one, 10, 10}, Processes} }.
% ... snip ... %
{% endcodeblock %}</p>

<p>This little snippet delegates the responsibility of all Webmachine-related stuff to the <code>app.config</code> file. Let's include this in our <code>Makefile</code> when we start our application.</p>

<p>{% codeblock Makefile (partial) lang:bash %}
webstart: app</p>

<pre><code>exec erl -pa $(PWD)/apps/*/ebin -pa $(PWD)/deps/*/ebin -boot start_sasl -config $(PWD)/apps/csd_web/priv/app.config -config $(PWD)/apps/csd_core/priv/app.config -s reloader -s csd_core -s csd_web
</code></pre>

<p>{% endcodeblock %}</p>

<p>All we've done here is add another <code>-config</code> parameter and pointed it at the new <code>app.config</code> file in the <code>csd_web/src</code> folder. Fire up the application and it <em>should</em> behave exactly as it did before.</p>

<p>Now that we have our configuration tweaked we have finalised the last of the refactoring tasks (at least for now). It's now time to start designing our user login functionality.</p>

<h2>Handling User Logins</h2>

<p>Handling logins isn't necessarily as simple as it looks. Remember, <a href="http://www.basho.com/developers.html#Webmachine" title="Webmachine">Webmachine</a> is not a Web application framework, it's a feature-rich tool which helps us build well-behaving RESTful HTTP applications. The idea of a "session" is a (leaky) abstraction that web developers have added to web applications to aid in preventing users from having to manually sign in each time they want to access a resource. This abstraction tends to be handled through cookies.</p>

<p>We'll be doing the same, but given that we don't have anything in place at all we're going to have to come up with our own method for handling authentication of the user via cookies.</p>

<p>Bearing in mind that we'll be making use of Twitter, via OAuth, to deal with the process of authentication, the login process will consist of the following steps:</p>

<ol>
<li>The user clicks a "login via Twitter" button.</li>
<li>The server handles the request and negotiates a <a href="http://oauth.net/core/1.0/#auth_step1" title="Request tokens">request token</a> with Twitter using OAuth.</li>
<li>The application redirects the user to Twitter on a special URL which contains OAuth request information.</li>
<li>The user is asked to sign in to Twitter, if they haven't already during the course of their browser session.</li>
<li>Twitter then confirms that the user does intend to sign-in to Code Smackdown using their Twitter credentials, and redirects the user back to the application.</li>
<li>If the user approves the process, the application is handed a verification token which is then used to generate an OAuth <a href="http://oauth.net/core/1.0/#auth_step3" title="Access tokens">access token</a> with Twitter. This access token is what is used to allow the user to easily sign in to the application from this point onward.</li>
</ol>


<p>Prepare yourself, you're about to learn how to do OAuth in Erlang! But before we can do that, we need to register our application with Twitter.</p>

<h3>Creating a new Twitter Application</h3>

<p>Start by browsing to the <a href="https://dev.twitter.com/apps/new" title="New Twitter Application">Twitter application registration page</a> and signing in with your Twitter account credentials. You'll be taken to a page where you can enter the details of the application. Set the <strong>Callback URL</strong> to <code>http://127.0.0.1:4000/oauth/callback</code> for now. This points the Twitter redirect traffic back to localhost which will make things easy during development. When it comes time to deploy the application to production you can change this to the proper callback address.</p>

<p><img src="/uploads/2012/02/twitter-app-create.png" title="Twitter app creation" alt="Creating an application in Twitter" /></p>

<p>Once you've filled out the details you'll being presented with a standard set of OAuth-related bits which we'll be using down the track. I'll of course be using my own registered application name (Code Smackdown) along with the keys. Given these keys are specific to my application and should be kept secret I will not be making them part of the source (sorry).</p>

<p>Once you're registered, we're ready to take the OAuth configuration information from Twitter and plug it into our own configuration. Re-open <code>csd_web/priv/app.config</code> and create a new section called <code>twitter</code> under the <code>csd_web</code> section and add the following</p>

<p>{% codeblock apps/csd_web/priv/app.config (partial) lang:erlang %}
% ... snip ... %
  {csd_web,</p>

<pre><code>[
  % ... snip ... %
  {twitter,
    [
      {consumer_key, "&lt; your application's key goes here &gt;"},
      {consumer_secret, "&lt; your application's secret goes here &gt;"},
      {request_token_url, "https://twitter.com/oauth/request_token"},
      {access_token_url, "https://twitter.com/oauth/access_token"},
      {authenticate_url, "https://twitter.com/oauth/authenticate"},
      {current_user_info_url, "https://twitter.com/account/verify_credentials.json"}
    ]
  }
]
</code></pre>

<p>  }
% ... snip ... %
{% endcodeblock %}</p>

<p>The first two values come straight from Twitter and would have been given to you upon registering your application. The rest are URLs that we'll be using later on when doing the OAuth handshake.</p>

<p>Now that we've got our configuration locked in we can get started on managing the requests. For this we need to understand how OAuth actually works.</p>

<p>A deep-dive into the ins and outs of OAuth is beyond the scope of this article. I recommend having a read of <a href="http://www.slideshare.net/leahculver/oauth-open-api-authentication" title="OAuth overview">this presentation on OAuth</a> which gives a good overview. The rest of this article will fill the gaps as to how it all works.</p>

<h3>Implementing OAuth</h3>

<p>Using OAuth requires us to invoke HTTP requests to Twitter. We could go through the pain of doing this manually, but instead we're going to use another Open Source utility which has the ability to handle this for us.</p>

<p><a href="https://github.com/tim/erlang-oauth" title="erlang-oauth">erlang-oauth</a> is an Erlang application which makes it easy to deal with OAuth requests and is ideal for what we need to do. Given that it will be a dependency on our application we need it to work nicely with rebar. Out of the box this isn't the case, so I have made a <a href="https://github.com/OJ/erlang-oauth/tree/rebarise" title="erlang-oauth rebar fork">fork</a> with a topic branch that has rebar-friendliness in it. We'll use this fork and branch in our application.</p>

<p>{% codeblock apps/csd_web/rebar.config lang:erlang %}
%%-<em>- mode: erlang -</em>-
{deps,
  [</p>

<pre><code>{oauth, ".*", {git, "git://github.com/OJ/erlang-oauth", {branch, "rebarise"}}},
{webmachine, ".*", {git, "git://github.com/basho/webmachine", "HEAD"}},
{erlydtl, ".*", {git, "git://github.com/OJ/erlydtl.git", "HEAD"}}
</code></pre>

<p>  ]
}.
{% endcodeblock %}</p>

<p>The <code>erlang-oauth</code> application requires <code>ssl</code> and <code>public_key</code> applications to be running for it to function properly, so we need to kick those applications off during start-up. We can do that by editing <code>csd_web.erl</code> like so:</p>

<p>{% codeblock apps/csd_web/src/csd_web.erl lang:erlang %}</p>

<p>%% @author OJ Reeves <a href="&#109;&#x61;&#x69;&#108;&#x74;&#111;&#58;&#111;&#106;&#64;&#98;&#x75;&#x66;&#102;&#101;&#114;&#101;&#100;&#46;&#105;&#111;">&#x6f;&#x6a;&#x40;&#x62;&#x75;&#102;&#102;&#101;&#x72;&#101;&#100;&#x2e;&#x69;&#111;</a>
%% @copyright 2012 OJ Reeves.</p>

<p>%% @doc csd_web startup code</p>

<p>-module(csd_web).
-author('OJ Reeves <a href="&#109;&#x61;&#105;&#108;&#x74;&#111;&#58;&#111;&#106;&#64;&#x62;&#117;&#102;&#x66;&#101;&#x72;&#x65;&#100;&#46;&#105;&#x6f;">&#111;&#106;&#x40;&#98;&#117;&#x66;&#102;&#x65;&#114;&#101;&#x64;&#46;&#x69;&#x6f;</a>').
-export([start/0, start_link/0, stop/0]).</p>

<p>ensure_started(App) ->
  case application:start(App) of</p>

<pre><code>ok -&gt;
  ok;
{error, {already_started, App}} -&gt;
  ok
</code></pre>

<p>  end.</p>

<p>%% @spec start_link() -> {ok,Pid::pid()}
%% @doc Starts the app for inclusion in a supervisor tree
start_link() ->
  start_common(),
  csd_web_sup:start_link().</p>

<p>%% @spec start() -> ok
%% @doc Start the csd_web server.
start() ->
  start_common(),
  application:start(csd_web).</p>

<p>%% @spec stop() -> ok
%% @doc Stop the csd_web server.
stop() ->
  Res = application:stop(csd_web),
  application:stop(webmachine),
  application:stop(mochiweb),
  application:stop(public_key), % stop new dependency
  application:stop(ssl),        % stop new dependency
  application:stop(crypto),
  application:stop(inets),
  Res.</p>

<p>start_common() ->
  ensure_started(inets),
  ensure_started(crypto),
  ensure_started(public_key), % start new dependency
  ensure_started(ssl),        % start new dependency
  ensure_started(mochiweb),
  application:set_env(webmachine, webmachine_logger_module, webmachine_logger),
  ensure_started(webmachine),
  ok.
{% endcodeblock %}</p>

<p>Interacting with Twitter now becomes quite simple. To handle talking to Twitter we'll create a new module, called <code>twitter.erl</code>, that does the dirty work. Let's take a look at the code then we'll walk through it.</p>

<p>{% codeblock apps/csd_web/src/csd_web.erl lang:erlang %}</p>

<p>%% @author OJ Reeves <a href="&#x6d;&#x61;&#x69;&#108;&#x74;&#111;&#x3a;&#111;&#106;&#64;&#98;&#x75;&#102;&#102;&#101;&#114;&#x65;&#100;&#x2e;&#105;&#111;">&#x6f;&#x6a;&#64;&#98;&#117;&#102;&#x66;&#101;&#x72;&#101;&#x64;&#x2e;&#x69;&#x6f;</a>
%% @copyright 2012 OJ Reeves</p>

<p>-module(twitter).</p>

<p>-author('OJ Reeves <a href="&#109;&#x61;&#105;&#108;&#116;&#x6f;&#x3a;&#x6f;&#x6a;&#x40;&#x62;&#x75;&#x66;&#x66;&#101;&#x72;&#x65;&#x64;&#x2e;&#x69;&#x6f;">&#x6f;&#106;&#64;&#x62;&#x75;&#102;&#102;&#101;&#114;&#101;&#x64;&#x2e;&#105;&#x6f;</a>').</p>

<p>-export([request_access/0, verify_access/3, get_current_user_info/2]).</p>

<p>request_access() ->
  TwitterConf = conf:get_section(twitter),
  RequestTokenUrl = proplists:get_value(request_token_url, TwitterConf),
  {ok, RequestResponse} = oauth:get(RequestTokenUrl, [], consumer(TwitterConf)),
  RequestParams = oauth:params_decode(RequestResponse),
  RequestToken = oauth:token(RequestParams),
  AuthenticateUrl = proplists:get_value(authenticate_url, TwitterConf),
  {ok, oauth:uri(AuthenticateUrl, [{"oauth_token", RequestToken}])}.</p>

<p>verify_access(RequestToken, RequestTokenSecret, Verifier) ->
  TwitterConf = conf:get_section(twitter),
  AccessTokenUrl = proplists:get_value(access_token_url, TwitterConf),
  {ok, AccessResponse} = oauth:get(AccessTokenUrl, [{"oauth_verifier", Verifier}], consumer(TwitterConf), RequestToken, RequestTokenSecret),
  AccessParams = oauth:params_decode(AccessResponse),
  AccessToken = oauth:token(AccessParams),
  AccessTokenSecret = oauth:token_secret(AccessParams),
  {ok, AccessToken, AccessTokenSecret}.</p>

<p>get_current_user_info(AccessToken, AccessTokenSecret) ->
  call_json_service(current_user_info_url, AccessToken, AccessTokenSecret).</p>

<p>% Extract a oauth-formatted consumer tuple from the given Twitter configuration.
consumer(TwitterConf) ->
  ConsumerKey = proplists:get_value(consumer_key, TwitterConf),
  ConsumerSecret = proplists:get_value(consumer_secret, TwitterConf),
  {ConsumerKey, ConsumerSecret, hmac_sha1}.</p>

<p>% Invoke a call to a JSON service on Twitter.
call_json_service(UrlKey, AccessToken, AccessTokenSecret) ->
  TwitterConf = conf:get_section(twitter),
  Url = proplists:get_value(UrlKey, TwitterConf),
  {ok, Response} = oauth:get(Url, [], consumer(TwitterConf), AccessToken, AccessTokenSecret),
  {{ "{{" }}<em>Version, 200, "OK"}, </em>Headers, Json} = Response,
  {ok, Json}.
{% endcodeblock %}</p>

<p>This might seem like a lot but there isn't much to it. Here's the run-down:</p>

<ul>
<li><p><code>request_access</code>: This function is what handles the first step in the OAuth negotiation process. It starts by loading the <code>twitter</code> configuration from our <code>app.config</code> file. The <code>twitter</code> section contains all the URLs we need to talk to Twitter</p>

<p>First we need to get hole of a <em>request token</em>, which is an identifier for an authorisation request that Twitter generates when we first start talking OAuth. We get th <code>request_token_url</code> from the configuration and we connect to Twitter, using <code>oauth:get</code> to kick the process off. Note the use of the <code>consumer</code> function, which simply takes our local <code>twitter</code> configuration and populates an <code>erlang-oauth</code>-friendly tuple with the details required to make OAuth requests on behalf of our application. This tuple contains our <em>consumer key</em>, the <em>consumer secret</em> and the signature method to use. We will always be using <code>hmac_sha1</code> as that's what Twitter currently requires.</p>

<p>Twitter reponds with a payload which includes the generated request token. We take that request token out of the payload and generate an Authentication URL. This URL contains information about the request that we started in the previous steps, along with the <code>authenticate_url</code> value loaded from configuration. If you remember back to our configuration you'll see that this <code>authenticate_url</code> is one that Twitter told us to use when we first registered our application and it resolves to <code>https://twitter.com/oauth/authenticate</code>.</p>

<p>This URL is returned to the caller and the calling code should redirect the user to this URL so that they can authenticate themselves with Twitter.</p></li>
<li><p><code>verify_access</code>: This function is what is called after the use has authenticated themselves with Twitter. The function expects both the <em>request token</em> and <em>request token secret</em> so that the result of the request can be validated with Twitter. Twitter also generates a "verifier" value as part of it's authentication process, and this value is what is passed in via the <code>Verifier</code> parameter.</p>

<p>After getting hold of the Twitter configuration an <em>access token</em> URL is generated. This URL contains all the information required to turn the <em>request token</em> into an <em>access token</em>. Once generated, this URL is then accessed via <code>erlang-oauth</code> and the payload that comes back from Twitter contains both the <em>access token</em> and the <em>access token secret</em>. Both of these are required from this point on to make requests to Twitter on behalf of the user.</p></li>
<li><p><code>get_current_user_info</code>: This is a small helper function which calls to Twitter via <code>erlang-oauth</code> and extracts the user details for the user. The payload contains the usual Twitter profile stuff such as Twitter ID, username, bio, tweet count, etc.</p></li>
</ul>


<p>Before we take a look at the Webmachine resource that will invoke this functionality, let's take a look at what we'll need to do with the tokens once we've got them.</p>

<p>For now, we are only going to store them, encrypted, in the user's cookie which we'll send down to the browser. This isn't "best practice" when it comes to storage of this kind of information, but for the sake of this blog post it will suffice. Later in the series we'll be doing more with this information and most likely removing some of the information from the cookie.</p>

<p>With this in mind, we need something that is able to write to and read from the user's cookies during a request. This module needs to be able to verify that a user's cookie is valid and that it hasn't expired. When writing and reading the module must also handle the encryption of the sensitive information.</p>

<p>Let's create this new module, called <code>cookie.erl</code>, inside <code>csd_web</code>. I'll break it up into it's functions so you can see what it's doing.</p>

<p>{% codeblock apps/csd_web/src/cookie.erl (partial) lang:erlang %}</p>

<p>%% @author OJ Reeves <a href="&#x6d;&#x61;&#105;&#x6c;&#116;&#111;&#58;&#111;&#x6a;&#64;&#98;&#117;&#x66;&#102;&#x65;&#x72;&#x65;&#100;&#x2e;&#105;&#x6f;">&#111;&#106;&#64;&#x62;&#117;&#102;&#102;&#101;&#114;&#x65;&#x64;&#46;&#105;&#111;</a>
%% @copyright 2012 OJ Reeves</p>

<p>-module(cookie).</p>

<p>-author('OJ Reeves <a href="&#109;&#97;&#x69;&#108;&#x74;&#x6f;&#x3a;&#x6f;&#106;&#x40;&#x62;&#x75;&#102;&#x66;&#101;&#114;&#x65;&#x64;&#x2e;&#x69;&#111;">&#x6f;&#x6a;&#64;&#x62;&#x75;&#x66;&#x66;&#x65;&#x72;&#x65;&#100;&#x2e;&#105;&#111;</a>').</p>

<p>-export([load_auth/1, store_auth/5]).</p>

<p>-define(AUTH_COOKIE, "<strong>CodeSmackdown</strong>Auth").
-define(AUTH_SALT, "27ed2d041cdb4b8b2702").
-define(AUTH_SECRET, "2d0431cd9bda5ba4b98271edcb2e7102").
-define(AUTH_EXPIRY_DAYS, 7).
-define(ENC_IV, &lt;&lt;207,94,217,158,198,63,132,205,35,187,246,2,56,122,250,33>>).
-define(ENC_KEY,
  &lt;&lt;110,56,121,28,235,159,77,154,160,5,130,210,204,32,26,224,255,86,101,71,61,3,
  66,69,30,39,42,0,116,93,204,99>>).
{% endcodeblock %}</p>

<p>Ignoring the usual headers/setup for the module, we can see a stack of defines. They are:</p>

<ul>
<li><code>AUTH_COOKIE</code>: This is the name of the cookie that will live in the browser. If you use a cookie editor you'll see this name appear as the name of the cookie once it's written.</li>
<li><code>AUTH_SALT</code>: This is a bunch of characters that will be used as a <a href="http://en.wikipedia.org/wiki/Salt_(cryptography)" title="Salt (crypto)">salt</a> for when we're generating the <a href="http://en.wikipedia.org/wiki/HMAC" title="HMAC">SHA MAC</a> from the user's cookie information.</li>
<li><code>AUTH_SECRET</code>: This is the key we'll be using when creating a <a href="http://en.wikipedia.org/wiki/HMAC" title="HMAC">SHA MAC</a> from the data we'll be pushing into the cookie. This is to make sure that the cookie hasn't been tampered with.</li>
<li><code>AUTH_EXPIRY_DAYS</code>: This is the number of days that the cookie is valid for.</li>
<li><code>ENC_IV</code>: This is the initialisation vector used when encrypting/decrypting the data in the cookie.</li>
<li><code>ENC_KEY</code>: This is the key that's used for encrypting/decrypting data that's in the cookie.</li>
</ul>


<p>Pretty simple stuff. Now let's take a look at a function that does something interesting.</p>

<p>{% codeblock apps/csd_web/src/cookie.erl (partial) lang:erlang %}
load_auth(ReqData) ->
  case wrq:get_cookie_value(?AUTH_COOKIE, ReqData) of</p>

<pre><code>undefined -&gt;
  {error, no_cookie};
V -&gt;
  Val = mochiweb_util:unquote(V),
  decode(Val)
</code></pre>

<p>  end.
{% endcodeblock %}</p>

<p><code>load_auth</code> is a function which attempts to load authentication information from the cookies stored in the <code>ReqData</code> parameter. <code>ReqData</code> is the <a href="http://wiki.basho.com/Webmachine-Request.html" title="Request data">request data</a> that comes from Webmachine. As you can see, the function attempts to read the cookie value from the request data using Webmachine's <a href="http://wiki.basho.com/Webmachine-Request.html" title="Request data">wrq</a> module. If it fails <code>undefined</code> is returned and we know that no cookie has been set. If a value is read, we munge the data into something usable and then attempt to decode it using the <code>decode</code> function explained further down.</p>

<p>This function returns either <code>{ok, &lt;Cookie Information&gt;}</code> or <code>{error, &lt;Reason&gt;}</code>.</p>

<p>{% codeblock apps/csd_web/src/cookie.erl (partial) lang:erlang %}
store_auth(ReqData, Id, Name, Token, TokenSecret) ->
  Value = mochiweb_util:quote_plus(encode(Id, Name, Token, TokenSecret)),
  Options = [</p>

<pre><code>%{domain, "codesmackdown.com"},
{max_age, 3600 * 24 * ?AUTH_EXPIRY_DAYS},
{path, "/"},
{http_only, true}
</code></pre>

<p>  ],
  CookieHeader = mochiweb_cookies:cookie(?AUTH_COOKIE, Value, Options),
  wrq:merge_resp_headers([CookieHeader], ReqData).
{% endcodeblock %}</p>

<p><code>store_auth</code> is the opposite to <code>load_auth</code> as it writes the user's information and token data to a cookie. The parameters to this function are:</p>

<ul>
<li><code>ReqData</code>: Webmachine's request data.</li>
<li><code>Id</code>: The user's Twitter ID. We'll be using this as a key later on to retrieve information from Riak.</li>
<li><code>Name</code>: The user's Twitter user name. We'll use this purely for display.</li>
<li><code>Token</code> and <code>TokenSecret</code>: Token information for making OAuth requests on behalf of this user.</li>
</ul>


<p>The first thing we do is call <code>encode</code> and pass in the last four arguments. This gives us an encrypted blob which we can store in a cookie. We then put down some basic information inside <code>Options</code>, including the expiry date. We then use <code>mochiweb_cookies</code> to generate a cookie with the name (<code>AUTH_COOKIE</code>), value and options.</p>

<p>Lastly we take the generated cookie header and merge that with the headers that already part of <code>ReqData</code> and produce a new request data object which is returned to the caller.</p>

<p>{% codeblock apps/csd_web/src/cookie.erl (partial) lang:erlang %}
encode(Id, Name, Token, TokenSecret) ->
  SecretInfo = encrypt({Token, TokenSecret}),
  CookieValue = {Id, Name, get_expiry(), SecretInfo},
  base64:encode(term_to_binary({CookieValue, ?AUTH_SALT, crypto:sha_mac(?AUTH_SECRET, term_to_binary([CookieValue, ?AUTH_SALT]))})).
{% endcodeblock %}</p>

<p>The <code>encode</code> function is rather self-explanatory. We start by encrypting the OAuth token information, we then generate a tuple which includes all the data we want to keep, convert it to binary and <a href="http://en.wikipedia.org/wiki/Base64" title="Base64">base64</a> encode it.</p>

<p>{% codeblock apps/csd_web/src/cookie.erl (partial) lang:erlang %}
decode(CookieValue) ->
  {Value={Id, Name, Expire, SecretInfo}, Salt, Sign} = binary_to_term(base64:decode(CookieValue)),
  case crypto:sha_mac(?AUTH_SECRET, term_to_binary([Value, Salt])) of</p>

<pre><code>Sign -&gt;
  case Expire &gt;= calendar:local_time() of
    true -&gt;
      {Token, TokenSecret} = decrypt(SecretInfo),
      {ok, {Id, Name, Token, TokenSecret}};
    false -&gt;
      {error, expired}
  end;
_ -&gt;
  {error, invalid}
</code></pre>

<p>  end.
{% endcodeblock %}</p>

<p>The <code>decode</code> function does a little more than its counterpart as there's validation built-in as well as decrypting. Firstly we do the inverse of the final steps of the <code>encode</code> function in that we base64 decode the data into binary and convert the resulting binary back to Erlang terms. We then break this value up into its components.</p>

<p>We then validate that the cookie hasn't been tampered with by calculating the <a href="http://en.wikipedia.org/wiki/HMAC" title="HMAC">SHA MAC</a> of the data that was retrieved. If this value doesn't match what is expected we indicate that the value is invalid. If the value is valid, we then make sure that the internal cookie value hasn't expired. If it hasn't, we return <code>{ok, &lt;data&gt;}</code>.</p>

<p>The rest of the functions are easy to understand, so here they are for the sake of completeness without explanation.</p>

<p>{% codeblock apps/csd_web/src/cookie.erl (partial) lang:erlang %}
get_expiry() ->
  {Date, Time} = calendar:local_time(),
  NewDate = calendar:gregorian_days_to_date(calendar:date_to_gregorian_days(Date) + ?AUTH_EXPIRY_DAYS),
  {NewDate, Time}.</p>

<p>encrypt(Value) ->
  crypto:aes_ctr_encrypt(?ENC_KEY, ?ENC_IV, term_to_binary([Value, ?AUTH_SALT])).</p>

<p>decrypt(Value) ->
  [V, ?AUTH_SALT] = binary_to_term(crypto:aes_ctr_decrypt(?ENC_KEY, ?ENC_IV, Value)),
  V.
{% endcodeblock %}</p>

<p>Phew! Now that's out of the way we have some back-end glue which we can use to perform some more interesting tasks. One thing that we really need to do is update the landing page template with something more meaningful than what we have now.</p>

<p>We'll start making use of <a href="http://github.com/evanmiller/erlydtl" title="ErlyDTL">ErlyDTL</a>'s hierarchical templates and implement a base template which our other templates will also make use of. Here it is in all its simplicity:</p>

<p>{% codeblock apps/csd_web/templates/base.dtl lang:html %}
&lt;!DOCTYPE html>
<html lang="en">
  <head></p>

<pre><code>&lt;title&gt;Code Smackdown - {{ "{" }}% block page_title %}{{ "{" }}% endblock %}&lt;/title&gt;
&lt;script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js" type="text/javascript"&gt;&lt;/script&gt;
&lt;script src="http://ajax.microsoft.com/ajax/jquery.templates/beta1/jquery.tmpl.min.js" type="text/javascript"&gt;&lt;/script&gt;
</code></pre>

<p>  </head>
  <body></p>

<pre><code>{{ "{" }}% block body_content %}{{ "{" }}% endblock %}
</code></pre>

<p>  </body>
</html>
{% endcodeblock %}</p>

<p>In this template we've included a couple of Javascript files that we'll be using later on as well as setting up a basic HTML5 page. <code>page_title</code> and <code>body_content</code> are the two sections that child templates can populate with their own content.</p>

<p>With that, let's go ahead and modify our default template so that it has something a little more meaninful in it:</p>

<p>{% codeblock apps/csd_web/templates/home.dtl lang:html %}
{{ "{" }}% extends 'base.dtl' %}</p>

<p>{{ "{" }}% block page_title %}Landing Page{{ "{" }}% endblock %}</p>

<p>{{ "{" }}% block body_content %}</p>

<pre><code>&lt;h1&gt;Welcome to Code Smackdown&lt;/h1&gt;
{{ "{" }}% if logged_in %}
&lt;p&gt;Welcome back {{ "{" }}{ user_name }}.&lt;/p&gt;
{{ "{" }}% else %}
&lt;p&gt;We require you to sign in via Twitter&lt;/p&gt;
&lt;p&gt;&lt;a href="{{ "{" }}{ logon_url }}" title="Sign in with Twitter"&gt;&lt;img src="http://si0.twimg.com/images/dev/buttons/sign-in-with-twitter-d.png"/&gt;&lt;/a&gt;&lt;p&gt;
{{ "{" }}% endif %}
</code></pre>

<p>{{ "{" }}% endblock %}
{% endcodeblock %}</p>

<p>Nothing sinister going on here, but there are a couple of things worth noting. The template now looks for a field called <code>logged_in</code>, and if it's <code>true</code> it renders a paragraph which contains the value in the <code>user_name</code> field. If the <code>logged_in</code> flag is false a link is provided which points to <code>logon_url</code> which ultimately points the user at the Twitter OAuth entry page.</p>

<p>We'll need to pass these values in when we render the template. Let's have a look at the changed section of <code>csd_web_resource</code>:</p>

<p>{% codeblock apps/csd_web/src/csd_web_resource.erl (partial) lang:erlang %}
% ... snip ... %
to_html(ReqData, State) ->
  Content = case cookie:load_auth(ReqData) of</p>

<pre><code>{ok, {_, Name, _, _}} -&gt;
  csd_view:home(Name);
_ -&gt;
  csd_view:home()
</code></pre>

<p>  end,
  {Content, ReqData, State}.
% ... snip ... %
{% endcodeblock %}</p>

<p>Yes this is quite a bit different to before. We are calling into our <code>cookie</code> module to find out if the user is logged in. If they are logged on we call <code>csd_view:home</code> with a single parameter <code>Name</code>, if they're not logged on the same function is called without any parameters.</p>

<p>The <code>csd_view</code> module is new and was created to abstract the idea of template rendering. All the ErlyDTL handling happens in <code>csd_view</code>. Let's take a look at it now.</p>

<p>{% codeblock apps/csd_web/src/csd_view.erl (partial) lang:erlang %}
%% @author OJ Reeves <a href="&#109;&#x61;&#x69;&#108;&#116;&#111;&#x3a;&#x6f;&#x6a;&#64;&#98;&#x75;&#x66;&#x66;&#101;&#114;&#x65;&#100;&#x2e;&#x69;&#x6f;">&#x6f;&#106;&#64;&#98;&#117;&#102;&#102;&#x65;&#114;&#x65;&#100;&#46;&#105;&#111;</a>
%% @copyright 2012 OJ Reeves</p>

<p>-module(csd_view).</p>

<p>-author('OJ Reeves <a href="&#109;&#x61;&#x69;&#x6c;&#116;&#x6f;&#x3a;&#x6f;&#x6a;&#64;&#98;&#x75;&#x66;&#102;&#x65;&#114;&#x65;&#100;&#x2e;&#105;&#111;">&#x6f;&#106;&#x40;&#98;&#117;&#102;&#102;&#101;&#114;&#101;&#100;&#x2e;&#x69;&#111;</a>').</p>

<p>-export([home/0, home/1]).</p>

<p>home() ->
  Params = [{logged_in, false}, {logon_url, conf:get_val(urimap, twitter_logon)}],
  {ok, Content} = home_dtl:render(Params),
  Content.</p>

<p>home(Name) ->
  Params = [{logged_in, true}, {user_name, Name}],
  {ok, Content} = home_dtl:render(Params),
  Content.
{% endcodeblock %}</p>

<p>Here we can see the two functions called <code>home</code> which were invoked in the <code>csd_web_resource</code> module. Most of this module is simple and uninteresting except for the use of <code>conf:get_val</code>. Templates need to know about paths when generating URLs in the markup. In our case, we're rendering links which point to internal routes which are specified in the dispatch list. Rather than hard-code URLs in the templates I decided to create another section in the <code>app.config</code> called <code>urimap</code>. The goal is to have an easy-to-access location for addresses which lives alongside the routes so that the maintainer of the application can update both at the same time should something need to change. Here's what the new section looks like.</p>

<p>{% codeblock apps/csd_web/priv/app.config (partial) lang:erlang %}
% ... snip ... %
  {csd_web,</p>

<pre><code>[
  % ... snip ... %
  {urimap,
    [
      {home, "/"},
      {twitter_logon, "/oauth/request"}
    ]
  },
  % ... snip ... %
</code></pre>

<p>{% endcodeblock %}</p>

<p>Accessing a link address is as simple as running <code>conf:get_val(urimap, &lt;link-id&gt;)</code>.</p>

<p>At this point we can build and run the application to see what the landing page looks like. To fire up the application you'll need three consoles:</p>

<ol>
<li>One for Riak. Riak has to be running behind the scenes because <code>Pooler</code> will connect on start. Only one node is necessary at this point. Run: <code>/path/to/riak/dev/dev1/bin/riak start</code></li>
<li>One for HAProxy. Run: <code>make proxystart</code></li>
<li>One for the CSD application. Run: <code>make webstart</code></li>
</ol>


<p>When you browse to <a href="http://127.0.0.1:4000">http://127.0.0.1:4000</a> you should see the following:</p>

<p><img src="/uploads/2012/02/home-loggedoff.png" title="Home - Logged Off" alt="Landing page when logged off" /></p>

<p>Clicking the link will result in an error at this point, so don't do it yet! We need to implement more resources, but first let's just stick the routes into the dispatch in preparation.</p>

<p>{% codeblock apps/csd_web/priv/app.config (partial) lang:erlang %}
{csd_web,
  [</p>

<pre><code>{web,
  [
    % ... snip ... %
    {dispatch,
      [
        {[], csd_web_resource, []},
        {["snippet", key], csd_web_snippet_resource, []},
        {["oauth", "request"], csd_web_request_resource, []},  % new route
        {["oauth", "callback"], csd_web_callback_resource, []} % new route
      ]
    }
  ]
},
% ... snip ... %
</code></pre>

<p>{% endcodeblock %}</p>

<p>Easily done. Now let's look at the implementation of the first handler which handles the <code>/oauth/request</code> URI, <code>csd_web_request_resource</code>.</p>

<p>{% codeblock apps/csd_web/src/csd_web_request_resource.erl lang:erlang %}
%% @author OJ Reeves <a href="&#x6d;&#x61;&#x69;&#x6c;&#116;&#111;&#x3a;&#x6f;&#x6a;&#x40;&#98;&#117;&#102;&#102;&#x65;&#114;&#x65;&#100;&#46;&#105;&#111;">&#x6f;&#106;&#x40;&#x62;&#117;&#x66;&#102;&#101;&#x72;&#101;&#x64;&#46;&#x69;&#111;</a>
%% @copyright 2012 OJ Reeves</p>

<p>-module(csd_web_request_resource).</p>

<p>-author('OJ Reeves <a href="&#109;&#x61;&#x69;&#x6c;&#x74;&#111;&#58;&#x6f;&#x6a;&#64;&#98;&#x75;&#x66;&#102;&#101;&#x72;&#101;&#x64;&#x2e;&#x69;&#111;">&#111;&#x6a;&#64;&#98;&#117;&#102;&#x66;&#101;&#114;&#101;&#100;&#x2e;&#x69;&#x6f;</a>').</p>

<p>-export([init/1, resource_exists/2, previously_existed/2, moved_temporarily/2]).</p>

<p>-include_lib("webmachine/include/webmachine.hrl").</p>

<p>init([]) ->
  {ok, undefined}.</p>

<p>resource_exists(ReqData, State) ->
  {false, ReqData, State}.</p>

<p>previously_existed(ReqData, State) ->
  {true, ReqData, State}.</p>

<p>moved_temporarily(ReqData, State) ->
  {ok, Url} = twitter:request_access(),
  {{ "{" }}{true, Url}, ReqData, State}.
{% endcodeblock %}</p>

<p>This module is quite lightweight, but has a little bit of magic in it that revolves around getting redirects to work. If you're not familiar with how 307 redirects work in Webmachine, take a quick side-glance at my <a href="http://buffered.io/posts/redirects-with-webmachine/" title="Redirects with Webmachine">Redirects with Webmachine</a> post.</p>

<p>Back? Ok. The extra line of code in the <code>moved_temporarily</code> function is where we invoke <code>twitter:request_access()</code> which goes to Twitter.com and gets a request token. The URL generated by this call is then passed back to Webmachine which will tell the caller's browser where to redirect to.</p>

<p>Build the app, fire up it up and click on the "Sign in via Twitter" button and you should see a screen that resembles this (assuming you're already signed in to Twitter):</p>

<p><img src="/uploads/2012/02/twitter-logon.png" title="Twitter - Logon Page" alt="Logging into CSD view Twitter" /></p>

<p>Exciting! We're nearly there. Don't click "Sign In" just yet because we don't yet have the callback set up to handle the result. Let's do that now. Here's the resource:</p>

<p>{% codeblock apps/csd_web/src/csd_web_callback_resource.erl lang:erlang %}
%% @author OJ Reeves <a href="&#109;&#97;&#x69;&#x6c;&#x74;&#111;&#x3a;&#111;&#x6a;&#x40;&#98;&#x75;&#102;&#x66;&#101;&#x72;&#101;&#100;&#46;&#105;&#111;">&#111;&#x6a;&#64;&#98;&#x75;&#102;&#102;&#101;&#x72;&#101;&#x64;&#x2e;&#x69;&#111;</a>
%% @copyright 2012 OJ Reeves</p>

<p>-module(csd_web_callback_resource).</p>

<p>-author('OJ Reeves <a href="&#109;&#x61;&#105;&#x6c;&#x74;&#x6f;&#x3a;&#111;&#x6a;&#x40;&#98;&#x75;&#x66;&#x66;&#x65;&#x72;&#x65;&#100;&#46;&#x69;&#111;">&#x6f;&#x6a;&#x40;&#98;&#x75;&#x66;&#x66;&#101;&#114;&#x65;&#x64;&#46;&#x69;&#111;</a>').</p>

<p>-export([init/1, resource_exists/2, previously_existed/2, moved_temporarily/2]).</p>

<p>-include_lib("webmachine/include/webmachine.hrl").</p>

<p>init([]) ->
  {ok, undefined}.</p>

<p>resource_exists(ReqData, State) ->
  {false, ReqData, State}.</p>

<p>previously_existed(ReqData, State) ->
  {true, ReqData, State}.</p>

<p>moved_temporarily(ReqData, State) ->
  handle_callback(ReqData, State).</p>

<p>handle_callback(ReqData, State) ->
  ReqToken = wrq:get_qs_value("oauth_token", ReqData),
  ReqTokenSecret = wrq:get_qs_value("oauth_token_secret", ReqData),
  Verifier = wrq:get_qs_value("oauth_verifier", ReqData),</p>

<p>  {ok, AccessToken, AccessTokenSecret} = twitter:verify_access(ReqToken, ReqTokenSecret, Verifier),
  {ok, UserInfoJson} = twitter:get_current_user_info(AccessToken, AccessTokenSecret),
  {struct, Json} = mochijson2:decode(UserInfoJson),
  UserId = proplists:get_value(&lt;&lt;"id">>, Json),
  UserName = proplists:get_value(&lt;&lt;"screen_name">>, Json),
  NewReqData = cookie:store_auth(ReqData, UserId, UserName, AccessToken, AccessTokenSecret),</p>

<p>  % TODO: store the 'session' in Riak in an ETS backend</p>

<p>  % TODO: error handlng for when things don't go to plan
  {{ "{" }}{true, conf:get_val(urimap, home)}, NewReqData, State}.</p>

<p>{% endcodeblock %}</p>

<p>The first few parts of this module should look familiar by now. We are overriding the <code>resource_exists</code>, <code>previously_existed</code> and <code>moved_temporarility</code> functions because we're going to be redirecting. For now we're going to assume that the user clicked "Sign In" and that everything went according to plan. Later on we'll worry about handling logon errors.</p>

<p>When <code>moved_temporarily</code> is invoked we pass responsibility off to the <code>handle_callback</code> function. Here you can see we are taking three parameters out of the query string that Twitter sent through to us. Those parameters are the <em>request token</em>, <em>request token secret</em> and the <em>verifier</em>. We take those values and pass them down to our <code>twittter</code> module to get it to verify the access with Twitter and to generate an <em>access token/access token secret</em> pair. When that comes back we have our token information and we can assume that the user has authenticated via Twitter. At this point we can "log the user on" by storing a cookie, but before we do that we want to get their Twitter ID and Username, so we invoke the <code>twitter:get_current_user_info</code> function, passing in the OAuth credentials, which in return gives us a blob of <a href="http://json.org/" title="JavaScript Object Notation">JSON</a> which contains the user's Twitter information.</p>

<p>From that we glean their ID and Username. We then store that information, along with the access token information, in a cookie using <code>cookie:store_ath</code> (which we've covered previously) and we get a new request data object out as a result.</p>

<p>Now all we have to do is redirect the user back to the home page and pass on the new request data. Webmachine will take this data and push the cookie to the user's browser, then redirect the user to the <code>home</code> entry in the <code>urimap</code> section in <code>app.config</code>. In effect, we're redirected to the home page as a logged on user.</p>

<p>Ignoring the <code>TODO</code> notes (which we'll cover in future posts in this series), we've got ourselves to the point where the application should function end-to-end. Finally.</p>

<p>Compile the application and fire it up! Let's take a look at what happens.</p>

<p><img src="/uploads/2012/02/home-loggedoff.png" title="Home - Logged Off" alt="Hitting the home page prior to logging on" /></p>

<p><img src="/uploads/2012/02/twitter-logon.png" title="Twitter - Logon Page" alt="Authenticating with Twitter" /></p>

<p><img src="/uploads/2012/02/home-loggedon.png" title="Home - Logged On" alt="Back home after the redirect with successful sign-on" /></p>

<h2>That's all ... for now</h2>

<p>Thanks for reading this post. If you managed to make it this far you've done well. In the next post we'll start to do some more meaningful things with our logged on users, such as allowing them to submit code snippets. This is where the end-to-end process becomes interesting.</p>

<p>Comments, feedback and criticisms are as welcome as always.</p>

<p><strong>Note:</strong> The code for Part 4 (this post) can be found on <a href="https://github.com/OJ/csd/tree/Part4-20120217" title="Source code for Part 4">Github</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[CorrugatedIron Update - v0.1.1]]></title>
    <link href="http://buffered.io/posts/corrugatediron-update-v0-1-1/"/>
    <updated>2011-08-03T21:18:00+10:00</updated>
    <id>http://buffered.io/posts/corrugatediron-update-v0-1-1</id>
    <content type="html"><![CDATA[<p>Last week <a href="http://facility9.com/" title="Jeremiah Peschka">JP</a> and I released our first Open Source project, <a href="http://corrugatediron.org/" title="CorrugatedIron">CorrugatedIron</a>. The release seemed to be fairly well received by those people who gave it a spin. We've had some good feedback along the way which we'll be evaluating, and no doubt those suggestions and comments will be influencing the future of the library.</p>

<p>In the interim, we wanted to get another version out which sorts out two main issues and that changes the <em>perceived</em> "norm" when building applications with CorrugatedIron. Those issues are listed below. We've also go the first pass of our <a href="http://corrugatediron.org/documentation/MapReduce.html" title="Map/Reduce">Map/Reduce</a> documentation ready.</p>

<p>If you're not interested in the detail, head on over to the <a href="http://corrugatediron.org/downloads.html" title="Downloads page">download page</a> to find out the many ways in which you can get access to the release. Otherwise, please read on!</p>

<!--more-->


<h2>Removal of IoC</h2>

<p>When we first put together the sample applications we thought that it'd be a good idea to show how these things can be done using what the mainstream .NET developers would use. That is, we decided to wire everything in with IoC. This wasn't because we felt that this is how it <strong>had</strong> to be done, but more to try and give people a level of familiarity. The library that we chose to use for the samples was Unity, for no other reason that "it was there".</p>

<p>This small mistake seemed to give off the impression that we felt that Unity was the best choice of all the IoC containers out there.</p>

<p>This is most definitely <strong>not the case</strong>. We are in no way advocating the use of one IoC container over the other. We honestly don't care which one you want to use. You should use whichever works for you.</p>

<p>To avoid this perception we decided that it would be best to remove references to any IoC container in all samples except for the <a href="https://github.com/DistributedNonsense/CorrugatedIron.Samples/tree/master/VisualStudio2010/Sample" title="IoC Sample Project">one sample</a> which shows how to use <em>lots</em> of different containers to do the same thing. Hence you should see a <em>lack</em> of IoC containers in our examples from now on. Sorry for any confusion.</p>

<h2>Handling of Client IDs</h2>

<p>Our first implementation of Client ID generation in CorrugatedIron wasn't a great implementation. We made the decision early on to generate IDs based on some details of the machine that the client was running on (ie. The MAC address of the first functioning NIC on the machine). Our thinking was that we wanted to uniquely identify a client while still allowing the ID to be reused across instances of the application. This might make sense for rich-client applications, but certainly doesn't work well in the web world. In a web environment, each request could come from a different user.</p>

<p>Almost immediately after releasing v0.1.0, <a href="http://facility9.com/" title="Jeremiah Peschka">JP</a> and I read an email on the [Riak mailing list][mailinglist] which made us rethink our approach. After a bit of discussion, we decided to go with an idea of Jeremiah's which involves the generation of the Client ID when the RiakClient instance is created. This generation can be controlled by the user of the library by specifying a <code>seed</code> value.</p>

<p>This gives the user the flexibility of not being concerned about the Client ID if they don't want to be, but can have some control if they do.</p>

<h2>Ease of Configuration</h2>

<p>The only bit of "constructive criticism" that we received on-masse was via <a href="http://news.ycombinator.com/item?id=2799823" title="CI on Hacker News">Hacker News</a> and revolved around configuration. The general feeling was that the effort required to configure the library was higher than expected, especially when compared to other libraries. I'd suggest reading the full discussion over on the <a href="http://news.ycombinator.com/item?id=2799823" title="CI on Hacker News">Hacker News</a> site to read some of the reasons behind the design decisions. But, if you're too lazy (I don't blame you if you are), the short version is this: CorrugatedIron is a .NET library connecting to a clustered, distributed key-value store. A library that does this, while attempting to manage load-balancing across all nodes in the cluster, is going to require some configuration.</p>

<p>One concern in particular resonated with me, and that was the difficulty in getting CorrugatedIron running inside a REPL, such as <a href="http://www.fsharphelp.com/Interactive.aspx" title="F# interactive">FSI</a>. The two issues with getting a REPL to work from configuration are:</p>

<ul>
<li>The ability to specify the location of the configuration file.</li>
<li>The number of lines of code it takes to wire things in.</li>
</ul>


<p>The XML that's required is not going to be changing in the short term. The values that are specified in that configuration are required to make the most of Riak and that's not something we're prepared to compromise on. However, the .NET code required to access it has changed, though the old way of wiring things in still exists for those people who want that level of flexibility.</p>

<p>In short, you can wire-in CorrugatedIron's XML configuration as simply as:</p>

<p>{% codeblock lang:csharp %}
var cluster = RiakCluster.FromConfig("riakConfig");
var client = cluster.CreateClient();
{% endcodeblock %}</p>

<h2>That's it!</h2>

<p>Hopefully this will make your life a little easier while getting CorrugatedIron up and running. We're always keen to hear your feedback, so please <a href="https://github.com/DistributedNonsense/CorrugatedIron" title="CorrugatedIron @ Github">drop us a line</a> if you have any thoughts, suggestions or issues.</p>

<p>Enjoy!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introducing CorrugatedIron]]></title>
    <link href="http://buffered.io/posts/introducing-corrugatediron/"/>
    <updated>2011-07-25T09:00:00+10:00</updated>
    <id>http://buffered.io/posts/introducing-corrugatediron</id>
    <content type="html"><![CDATA[<h2>It's Alive!</h2>

<p>It is with great pride that I introduce my first ever Open Source product release: <a href="http://corrugatediron.org/" title="CorrugatedIron">CorrugatedIron</a>! A feature-rich .NET client for the <a href="http://riak.basho.com/" title="Riak">Riak</a> Key-Value store. Together with my partner-in-crime <a href="http://facility9.com/" title="Jeremiah Peschka">Jeremiah</a>, we've put together a driver which exposes a great deal of Riak's functionality. CorrugatedIron is at <a href="https://github.com/DistributedNonsense/CorrugatedIron/tree/v0.1.0">v0.1.0</a>, and while it doesn't support every feature the Riak has to offer, it covers most, if not all, of the most common features that are required to effectively communicate with the system.</p>

<!--more-->


<h2>Features</h2>

<p>I would love to cover off all of the features here, but we've already done it on the <a href="http://corrugatediron.org/" title="CorrugatedIron">official site</a>, so head over there to take a look at the feature list, documentation and sample projects.</p>

<h2>The What, Where, Why and How</h2>

<h3>How it all began</h3>

<p>I don't remember the exact date that I was first exposed to <a href="http://riak.basho.com/" title="Riak">Riak</a>, <a href="http://basho.com/" title="Basho">Basho</a>'s bomb-proof database, but I do remember being very impressed. It was around the time I really started to get an interest in <a href="http://www.erlang.org/" title="Erlang">Erlang</a> programming, so it probably isn't a surprise, given that Riak is written in Erlang, that it piqued my interest. I have a bit of a fascination with systems that don't stop, and Riak fits firmly in that category.</p>

<p>So after playing with it for a while and marvelling at the sturdiness, the ease of set-up (even with clustering), the clever architecture and the make-up of the system, I realised that Riak was actually pretty special. Almost in a class of it's own. Its properties really appealed to me, and I felt the need to do something with.</p>

<p>Back then, I wasn't even working with Erlang professionally. The clients that I had at the time were pure .NET shops and didn't feel the need to consider anything other than the "tried and true" <a href="http://en.wikipedia.org/wiki/Relational_database_management_system" title="Relational Databases">RDBMS</a> (which in Brisbane seems to be mainly MS SQL, particularly in the .NET circles). Given that the likelihood of my working with Riak in a professional sense in the short term was fairly slim, I wanted to look to other areas where I could work with it and contribute to it at the same time. Needless to say, my Erlang-fu wasn't (and still isn't) up to scratch, so contributing to Riak itself wasn't yet something I thought I could take on. I needed something else.</p>

<p>Late last year, I was starting to look for projects that I could build and release as <a href="http://www.opensource.org/" title="Open Source">Open Source</a>. I have, on my occasions, contributed to other Open Source projects but I hadn't worked on one of my own and released it into the wild. This is something that I really wanted to do and so was looking for something to build.</p>

<p>During my travels in the Riak circles I had noticed that there were quite a few clients available which allowed people to talk to Riak from various languages. Basho themselves <a href="http://wiki.basho.com/Client-Libraries.html" title="Client libraries">support</a> ones for Erlang, Java, PHP, Python and Ruby, and there are many more listed on the <a href="http://wiki.basho.com/Community-Developed-Libraries-and-Projects.html#Client-Libraries-and-Frameworks" title="Client libraries">Riak community clients page</a> which cover languages like C, Clojure, Go, Node.js, Perl, Scala and more.</p>

<p>Amongst this libraries there were two listed for .NET. Both of them seemed to have a small set of functionality, they both weren't finished and at the time they both had not been touched for quite a while. In short, for .NET people, there really wasn't a viable option for Riak connectivity. What a travesty!</p>

<p>I remember sending an email to <a href="http://twitter.com/pharkmillups" title="Mark Phillips">Mark</a> telling him that I was pondering the thought of building this library to make sure that there wasn't already someone else out there making a go of it. He was aware of the two existing solutions but didn't know what the plans were with them, and he wasn't aware of any others at the time. This was all the validation that I needed.</p>

<p>So, in late 2010, I decided that the first project I wanted to build and release to the world as an Open Source application was a .NET client for Riak, one that worked on both the <a href="http://en.wikipedia.org/wiki/Common_Language_Runtime" title="Microsoft CLR">CLR</a> and on <a href="http://www.mono-project.com/" title="Mono">Mono</a>. This is where CorrugatedIron was conceived.</p>

<h3>So why the long wait?</h3>

<p>If you look at the <a href="https://github.com/DistributedNonsense/CorrugatedIron/graph">history</a> of the code-base you'll see that I had an initial flurry of activity in early 2011, but didn't really do anything else for quite some time. There's a reason for that!</p>

<p>When I first decided on the project, I spent a bit of time thinking about the design. I wanted the interface to be more "functional" in many ways. I wanted to remove the idea of resource management away from the caller. I didn't want to give them rope (such as <code>IDisposable</code> instances) with which to hang themselves (such as forgetting to <code>Dispose()</code>). I wanted the interface to be clean, simple, intuitive and safe.</p>

<p>This little in-memory design session went on for quite some time, but I didn't really put anything down on paper. Nor did I write any code. Instead, I though that I would put something together which wasn't really related or as important as the API. Something that was lower level which the user of the library would not (and should not) see.</p>

<p>A Riak node has two interfaces which clients can connect to. One of them is a <a href="http://en.wikipedia.org/wiki/Representational_State_Transfer" title="REST">REST</a> API, and the other is a binary API which utilises <a href="http://code.google.com/p/protobuf/" title="Protocol Buffers">Protocol Buffers</a>. I thought that it would be fun to start working on the Protocol Buffer handling while the idea of the API formed slowly in the back of my mind.</p>

<h3>Then along came JP</h3>

<p>Then, just before Christmas (23rd December to be exact) I received an email out of the blue from a chap in America. Here's how it started:</p>

<blockquote><p>Greetings from America!</p>

<p>Hope your summer is going well. Mark Phillips told me that you were interested in working on a good .net driver for Riak. Have you made any progress or is it still a general idea in your head?</p></blockquote>

<p>There was much more to the email than that, but it certainly started off well! The email was from <a href="http://facility9.com/" title="Jeremiah Peschka">Jeremiah Peschka</a>, a chap who's name I had seen floating around the Riak <a href="http://lists.basho.com/mailman/listinfo/riak-users_lists.basho.com" title="Riak mailing list">mailing list</a>. In fact, I remember his name catching my eye on more than one occasion because his email signature contained the following:</p>

<blockquote><p>Microsoft SQL Server MVP<br/>
MCITP: Database Developer, DBA</p></blockquote>

<p>This resonated with me because he was obviously into RDBMSs, but hadn't been a complete asshat on a list full of people working with <a href="http://en.wikipedia.org/wiki/NoSQL" title="NoSQL">NoSQL</a>. This was a rare and surprising thing.</p>

<p>Moving on. After a few email exchanges, Jeremiah indicated that he was interested in helping to build CorrugatedIron (despite the whacky name) and we decided to team up. I knew that he'd definitely add value to the whole process and would also keep me motivated. Plus, his obvious skills in the SQL realm would no doubt be useful too!</p>

<p>We continued to talk into January and I thought that it was past time that I shared the code that I had hacked together so that we had a starting/talking point. On the 7th January, I committed my first <a href="https://github.com/DistributedNonsense/CorrugatedIron/--SOMETHING-GOES-HERE--">batch of code</a> to the repository which contained a stack of very untested code. I don't even know if it worked! The result: we had a lot to talk about.</p>

<h3>Another intermission</h3>

<p>Though JP and I continued to talk a great deal via email, we were both quite under the pump with our respective places of employment. We shared ideas along the way, but neither of us were really into the project as a result of the intense work we had on elsewhere. Though I'm fairly certain that the thought of the project wasn't far from our minds the whole time.</p>

<p>Then on the 12th April, out of the blue again, another email came. I'm not going to divulge all the detail, but the crux of it indicated that there was a growing interest in seeing a .NET client for Riak from people in other areas of the world. It also asked what the story was with the client that we were building, and wondered if we had a timeline down with a potential release date.</p>

<p>This was scary, exciting and a slap in the face at the same time. Scary and exciting because there was a possibility that someone out there might want to use what we were building. A slap in the face because we hadn't really done much at all other than the initial commit and a great deal of talking. It was just the wake up call that we needed.</p>

<p>I spoke to JP about the email and we both decided that it was well past time to get our heads down and start working on this thing for real. We needed to lock in a set of features, a time-frame for development and, most importantly, a release date.</p>

<p>So, we did!</p>

<h3>All ahead flank</h3>

<p>In early May, JP and I managed to start freeing up time that we could then contribute to our project. Development ramped up and kicked off in mid-May, and on the 18th, we committed our first changeset to the repository since the very first commit in January. From there, we went nuts!</p>

<p>We consistently worked on things and pushed our code back and forth for the latter half of May and well in to June. At this point, things really started to get exciting.</p>

<p>We had managed to get quite a few features out in a small period of time, and were generally very happy with our progress. JP was making the most of his superior Riak knowledge and was banging out API features like there was no tomorrow. Meanwhile, I had my head down in the guts of the underlying bits, trying to keep things sane.</p>

<p>It was at this point we were told of <em>more</em> people who were keen to get their hands on a quality .NET client, and that if we could get the client ready in time, various individuals would be happy to talk about it during <a href="http://oscon.com/" title="OSCON">OSCON</a>, the biggest Open Source convention I know of. Awesome! This was an opportunity too good to miss.</p>

<p>We finalised our feature-set for v0.1.0, wrote down our final time-line and informed various parties of what we were planning to do. It was locked in. We were heads down, bums-up trying to get things into shape. It was all very exciting.</p>

<h3>Even more interest</h3>

<p>By early July, we had somehow managed to attract the attention of two more individuals who were looking for this functionality. Both of which put their hands up to the opportunity to look at our Alpha software, take it for a spin and give us some feedback. This was awesome. Having other people look over the code and critique it while, in some ways, evaluating it for their own needs is a great thing.</p>

<p>After a short period of time, we received very constructive (and, just quietly, rather gratifying) comments from both guys. It made us feel like we couldn't be doing too badly!</p>

<p>We opened up the repository to them so that they could get the latest code whenever they wanted, and also opened it up to some of the Basho guys so that they could also cast their eyes over it. The cat was slowly coming out of the bad.</p>

<p>On the 20th July, we locked in the feature-set for v0.1.0 and froze the codebase for all but minor changes, bug fixes and tweaks. It was time to do what everyone <em>loves</em> to do: <strong>documentation</strong>.</p>

<p>Given that I tend to hate documentation, straight away I was looking for something else to fill the time with. Thankfully, alongside documentation, we also needed a few sample applications (let's face it, as devs we learn much faster from working code compared to reams of documentation). So I leapt on the opportunity to crank out <a href="https://github.com/DistributedNonsense/CorrugatedIron.Samples/tree/master/VisualStudio2010/Sample.YakRiak" title="YakRiak.NET">YakRiak.NET</a>, a .NET client for <a href="https://github.com/seancribbs" title="Sean Cribbs">Sean Cribbs</a>' <a href="https://github.com/seancribbs/yakriak" title="The original YakRiak">YakRiak</a> chat application. It was incredibly simple to do and didn't take very long at all. When building the app, and finally <em>using</em> my own software, I have to admit I felt pretty good. It was nice to use my own software for something fun!</p>

<p>After that, JP put together a new <a href="https://github.com/peschkaj/CorrugatedIron.Samples/tree/master/VisualStudio2010/Sample.SessionStateProvider">Session State Provider</a> which used Riak as the back-end store. How good is that! Riak-backed session state in .NET. Awesome sauce.</p>

<p>I also finalised a small sample application which utilised some of the most common IoC frameworks to wire in the configuration, and began working on the 'real' documentation again.</p>

<h3>"Going live"</h3>

<p>Finally, on the 25th July, after a couple of months of intense development, sample app creation, documentation and blog posts, CorrugatedIron was released to the world -- just in time for OSCON (phew!).</p>

<p>While the documentation isn't as thorough as we would like, and our unit test coverage isn't as high as we'd like, we're very happy with what we've managed to achieve. This first release is by no means the last, and JP and I are both excited about what we're going to add to it in the future.</p>

<h3>A small side note</h3>

<p>When people first start working on projects like this there is always a risk that personalities will clash and the software will suffer. JP and I knew nothing of each other when we started this thing, yet over time have got to know each other and had a great deal of fun learning from each other. I think I've been really fortunate in having JP involve himself in this project. He has been open to different ideas and opinions, has never come across as an ass and has been a real pleasure to work with the whole time.</p>

<p>So, JP, thanks mate! I'm really glad you got involved. CorrugatedIron wouldn't be what it is now if you hadn't.</p>

<h3>The End</h3>

<p>Thanks for reading this far! If you're a .NET mofo and you're keen to get your Riak on, <a href="https://github.com/DistributedNonsense/CorrugatedIron" title="Source code">grab the source</a>, <a href="https://github.com/DistributedNonsense/CorrugatedIron/downloads" title="Binary downloads">download the binaries</a> or <a href="http://www.nuget.org/List/Packages/CorrugatedIron" title="Nuget package">install the Nuget package</a> and get cracking! Feedback is always welcome, as are patches. So if you've got something to add, take away or refine, fork our <a href="https://github.com/DistributedNonsense/CorrugatedIron" title="Source code">repository</a> and get those pulls requests happening!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Webmachine, ErlyDTL and Riak - Part 3]]></title>
    <link href="http://buffered.io/posts/webmachine-erlydtl-and-riak-part-3/"/>
    <updated>2010-10-13T06:31:00+10:00</updated>
    <id>http://buffered.io/posts/webmachine-erlydtl-and-riak-part-3</id>
    <content type="html"><![CDATA[<p><img src="http://buffered.io/uploads/2010/09/riak-logo.png" alt="Riak Logo" style="float:left;padding-right:5px;padding-bottom:5px;"/>For those of you who are new to the series, you may want to check out <a href="/posts/webmachine-erlydtl-and-riak-part-1/" title="Wembachine, ErlyDTL and Riak - Part 1">Part 1</a> and <a href="/posts/webmachine-erlydtl-and-riak-part-2/" title="Wembachine, ErlyDTL and Riak - Part 2">Part 2</a> before reading this post. It will help give you some context as well as introduce you to some of the jargon and technology that I'm using. If you've already read then, or don't want to, then please read on!</p>

<p>This post builds on the previous two, but not without a few little modifications. If you're interested in following along step by step with your own version of the code running, then get yourself a copy of <a href="https://github.com/OJ/csd/tree/Part2-20110403" title="Source code for Part 2">this changeset</a> before doing so.</p>

<p>In this post we're going to cover:</p>

<ol>
<li>A slight refactor of code structure to support the "standard" approach to building applications in Erlang using OTP.</li>
<li>Building a small set of modules to talk to <a href="http://www.basho.com/developers.html#Riak" title="Riak">Riak</a>.</li>
<li>Creation of some <a href="http://json.org/" title="JavaScript Object Notation">JSON</a> helper functions for reading and writing data.</li>
<li>Calling all the way from the <a href="http://www.basho.com/developers.html#Webmachine" title="Webmachine">Webmachine</a> front-end to Riak to extract data and display it in a browser using <a href="http://github.com/evanmiller/erlydtl" title="ErlyDTL">ErlyDTL</a> templates.</li>
</ol>


<p>There are quite a few code snippets in this post as well as output from script executions and <code>bash</code> sessions. To avoid confusion, all file listings reference the path to the file that is being modified relative to the root of the project folder.</p>

<p>Be warned, this is a <em>long</em> post :) Get yourself a <em>shmoke und a pancake</em>, a glass of your favourite beverage and put some relaxing music on (instrumental is best).</p>

<p>Are you ready? OK, here we go ...</p>

<!--more-->


<h2>A Slight Refactor</h2>

<p>I was ready to embark on this third post a while back but then I sat back and thought about how I might structure things if I were using another set of technologies. Usually I would put another layer between the web tier and the back-end database cluster as opposed to having the web tier talk to the database directly. It didn't make sense to me that this approach would be any different in Erlang.</p>

<p>I had a chat to <a href="http://twitter.com/sj_mackenzie" title="Stewart Mackenzie on Twitter">two</a> <a href="http://twitter.com/MatthewErbs" title="Matt Erbs on Twitter">blokes</a> that I really respect to get their views, and then I fired off a question to the Basho guys (via the <a href="irc://irc.freenode.com/riak" title="Riak IRC on Freenode">#riak IRC channel</a>). The Basho lads even made the effort to respond to me via the <a href="http://lists.basho.com/pipermail/riak-users_lists.basho.com/2010-September/001984.html" title="Riak Recap">Riak Recap</a> as they weren't available at the time to answer me via IRC (thanks again <a href="http://twitter.com/pharkmillups" title="Mark Phillips on Twitter">Mark</a>). All three of them confirmed my thoughts. Here's what appeared in the recap which captures the question and response nicely:</p>

<blockquote><p>Q --- I have a Webmachine application which will be talking to Riak. I was going to put application and controller logic in that application and I am wondering if [I] should instead be creating a "core" OTP application with the business style logic in it and have the Webmachine app talk to that app which, in turn, talks to Riak? Is that the general approach that is taken [in Erlang applications]? (from TheColonial via #riak)</p>

<p>A --- We recommend going with the latter approach. You're better off to create a core app that talks to Webmachine and Riak separately.</p></blockquote>

<p>Perfect, that makes total sense. Therefore the following describes what I did to modify the code base that I had in order to support this set up. <strong>Any failure</strong> in implementation, structure or understanding is totally my own and in no way reflects on the abilities and advice of those mentioned above who took the time to offer assistance.</p>

<p>Moving on. What we want to end up with is three applications:</p>

<table cellspacing="0">
  <thead>
    <tr>
      <th style="text-align:center;">Application</th>
      <th style="text-align:center;">Structure/Responsibility</th>
      <th style="text-align:center;">Talks to</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Riak</td>
      <td>Bomb-proof data storage and replication.</td>
      <td style="text-align:center">-</td>
    </tr>
    <tr>
      <td>csd_core</td>
      <td>An OTP application that provides an API to a set of logic that deals with the transformation of data from a client through to the database. It should keep the clients ignorant of the data storage medium. It should provide business logic that would be required for any client application to be able to talk to a `csd`/Riak back-end.</td>
      <td style="text-align:center">Riak</td>
    </tr>
    <tr>
      <td>csd_web</td>
      <td>Provide a nice, web-based interface for the user to experience the goal of the Code Smackdown application.</td>
      <td style="text-align:center">csd_core</td>
    </tr>
  </tbody>
</table>


<p>Given that we're going to be using this structure, the "root" folder should actually be fairly clean without any source. Instead, each <code>csd</code>-related application should live in its own sub-folder under an <code>apps</code> folder and the root should just contain the means to build it and start it. In essence what we'd like to see in the root folder is something like this:</p>

<pre><code>oj@spawn-link ~/blog/csd $ ls -F
apps/  dev.haproxy.conf  Makefile  proxy.sh*  rebar*  rebar.config  start.sh*
</code></pre>

<p>With that in mind, let's start the surgery.</p>

<h3>Moving csd to csd_web</h3>

<p>There are two ways to approach this problem. The first is to do a <strong>find and replace</strong>, making sure you cover off file names as well as module names, etc. The second is to simply <strong>recreate the web site from scratch</strong>, copy over any missing files and make any other adjustments manually that may be required.</p>

<p>I preferred the second approach, so that's what I did. First I recreated the web application, which is now called <code>csd_web</code> in the <code>apps</code> folder:</p>

<pre><code>oj@spawn-link ~/blog/csd $ mkdir apps &amp;&amp; cd apps
oj@spawn-link ~/blog/csd/apps $ ~/blog/webmachine/scripts/new_webmachine.sh csd_web .
==&gt; priv (create)
Writing /home/oj/blog/csd/apps/csd_web/README
Writing /home/oj/blog/csd/apps/csd_web/Makefile
Writing /home/oj/blog/csd/apps/csd_web/rebar.config
Writing /home/oj/blog/csd/apps/csd_web/rebar
Writing /home/oj/blog/csd/apps/csd_web/start.sh
Writing /home/oj/blog/csd/apps/csd_web/ebin/csd_web.app
Writing /home/oj/blog/csd/apps/csd_web/src/csd_web.erl
Writing /home/oj/blog/csd/apps/csd_web/src/csd_web_app.erl
Writing /home/oj/blog/csd/apps/csd_web/src/csd_web_sup.erl
Writing /home/oj/blog/csd/apps/csd_web/src/csd_web_resource.erl
Writing /home/oj/blog/csd/apps/csd_web/priv/dispatch.conf
oj@spawn-link ~/blog/csd/apps $ ls -F
csd_web/
</code></pre>

<p>Next I removed a few files which weren't going to be needed any more. I then copied over <code>rebar.config</code>, the ErlyDTL templates and the <code>csd.app.src</code> file (which we need to modify):</p>

<pre><code>oj@spawn-link ~/blog/csd/apps $ cd csd_web
oj@spawn-link ~/blog/csd/apps/csd_web $ rm README rebar start.sh
oj@spawn-link ~/blog/csd/apps/csd_web $ cp ../../rebar.config .
oj@spawn-link ~/blog/csd/apps/csd_web $ cp -R ../../templates .
oj@spawn-link ~/blog/csd/apps/csd_web $ cp ../../src/csd.app.src ./src/csd_web.app.src
</code></pre>

<p>I then edited the <code>csd_web.app.src</code> file so that the names were updated (I tidied it up a little and added a version number too):</p>

<p>{% codeblock apps/csd_web/src/csd_web.app.src lang:erlang %}
%%-<em>- mode: erlang -</em>-
{application, csd_web,
  [</p>

<pre><code>{description, "The Webmachine component of the Code Smackdown application."},
{vsn, "0.0.1"},
{modules, []},
{registered, []},
{applications,
  [
    kernel,
    stdlib,
    crypto,
    mochiweb,
    webmachine
  ]
},
{mod, {csd_web_app, []}},
{env, []}
</code></pre>

<p>  ]
}.
{% endcodeblock %}</p>

<p>I then opened up <code>csd_web_resource.erl</code> and made it look like the original <code>csd_resource.erl</code> so that it called the ErlyDTL template:</p>

<p>{% codeblock apps/csd_web/src/csd_web_resource.erl lang:erlang %}
-module(csd_web_resource).
-export([init/1, to_html/2]).</p>

<p>-include_lib("webmachine/include/webmachine.hrl").</p>

<p>init([]) ->
  {ok, undefined}.</p>

<p>to_html(ReqData, State) ->
  {ok, Content} = sample_dtl:render([{param, "Slartibartfast"}]),
  {Content, ReqData, State}.
{% endcodeblock %}</p>

<p><code>csd_web</code> is now ready to go. To build it, we need to go back up to the root <code>csd</code> folder and adjust the <code>rebar.config</code> so that it knows to look in the <code>apps</code> sub-folder (thanks to <a href="http://twitter.com/andrewtj" title="AndrewTJ on Twitter">Andrew</a> for <a href="http://lists.basho.com/pipermail/rebar_lists.basho.com/2010-October/000246.html" title="Configuring the Rebar apps folder on Basho list">pointing this out</a>). We can also remove all the dependencies because that will be taken care of by <code>csd_web</code>:</p>

<p>{% codeblock rebar.config lang:erlang %}
%%-<em>- mode: erlang -</em>-
{sub_dirs, ["apps/csd_web"]}.
{% endcodeblock %}</p>

<p>Next, I removed all the other left-over stuff in the root folder that wasn't required any more (including the startup script):</p>

<pre><code>oj@spawn-link ~/blog/csd $ rm -rf README priv src templates start.sh
</code></pre>

<p>I then modify the <code>Makefile</code> so that it does a couple of other things:</p>

<ol>
<li>Includes a target which builds just the current applications <em>without</em> building the dependencies (this will make builds much quicker most of the time).</li>
<li>Includes a target which can start the web application, essentially replacing the original startup script. This target will be dependent on the previous target so that it is always up to date when running the application.</li>
<li>Includes targets which can start/stop <code>HAproxy</code>.</li>
</ol>


<p>{% codeblock Makefile %}
ERL ?= erl
APP = csd</p>

<p>.PHONY: deps</p>

<p>all: deps
  @./rebar compile</p>

<p>app:
  @./rebar compile skip_deps=true</p>

<p>deps:
  @./rebar get-deps</p>

<p>clean:
  @./rebar clean</p>

<p>distclean: clean
  @./rebar delete-deps</p>

<p>webstart: app
  exec erl -pa $(PWD)/apps/<em>/ebin -pa $(PWD)/deps/</em>/ebin -boot start_sasl -s reloader -s csd_web</p>

<p>proxystart:
  @haproxy -f dev.haproxy.conf
{% endcodeblock %}</p>

<p>All that is left to do is start <code>haproxy</code> and launch the application (make sure <code>Riak</code> is running first). These commands need to be done in two different terminal windows. First, start the proxy (note the use of <code>sudo</code> so that we can listen on port 80):</p>

<pre><code>oj@spawn-link ~/blog/csd $ sudo make proxystart
[2] 1935
Available polling systems :
     sepoll : pref=400,  test result OK
      epoll : pref=300,  test result OK
       poll : pref=200,  test result OK
     select : pref=150,  test result OK
Total: 4 (4 usable), will use sepoll.
Using sepoll() as the polling mechanism.
</code></pre>

<p>Then make and start the web application. We have to do a full <code>make</code> first time around so that all the dependencies are resolved:</p>

<pre><code>oj@spawn-link ~/blog/csd $ make &amp;&amp; make webstart

   ... snip ...

=PROGRESS REPORT==== 4-Apr-2011::21:04:18 ===
         application: csd_web
          started_at: nonode@nohost
</code></pre>

<p>Now we should be able to hit <a href="http://localhost/" title="localhost web app">localhost</a> and see the ErlyDTL template rendered in all its awesome, black-and-white glory:</p>

<p><img src="http://buffered.io/uploads/2010/10/localhost-slartibartfast.png" /></p>

<p>Refactor complete. Now let's start work on our new OTP application which will be responsible for talking to Riak.</p>

<p>If you need a break, now is the time to take it! Go freshen up, take a leak and refill your glass.</p>

<p>Ready to go again? Here we go ...</p>

<h3>Creating the csd_core OTP Application</h3>

<p>Creation of an OTP-compliant application is another job for <a href="http://www.basho.com/developers.html#Rebar" title="Rebar">Rebar</a> as it comes with a set of templates built-in. Unfortunately those template aren't 100% and hence don't do everything we need to do out of the box. But we shall use them as a starting point:</p>

<pre><code>oj@spawn-link ~/blog/csd $ mkdir apps/csd_core &amp;&amp; cd apps/csd_core
oj@spawn-link ~/blog/csd/apps/csd_core $ ../../rebar create-app appid=csd_core
==&gt; csd_core (create-app)
Writing src/csd_core.app.src
Writing src/csd_core_app.erl
Writing src/csd_core_sup.erl
</code></pre>

<p>We have a very simple application shell set up, but we need to do a bit more work to get it ready. First, let's create our base <code>csd_core.erl</code> module which is used to fire up our application. For this we will use <code>csd_web.erl</code> (the one which is part of our Webmachine application) as a template. Note that I've shuffled things around and removed some things that are not relevant:</p>

<p>{% codeblock apps/csd_core/src/csd_core.erl lang:erlang %}
%% @author OJ Reeves <a href="&#x6d;&#x61;&#x69;&#x6c;&#116;&#111;&#x3a;&#x6f;&#x6a;&#64;&#x62;&#x75;&#102;&#x66;&#x65;&#x72;&#x65;&#x64;&#x2e;&#105;&#x6f;">&#111;&#x6a;&#64;&#98;&#117;&#x66;&#x66;&#101;&#x72;&#x65;&#x64;&#46;&#x69;&#111;</a>
%% @copyright 2011 OJ Reeves</p>

<p>%% @doc csd_core startup code</p>

<p>-module(csd_core).
-author('OJ Reeves <a href="&#109;&#x61;&#x69;&#108;&#x74;&#111;&#x3a;&#111;&#106;&#64;&#x62;&#x75;&#x66;&#102;&#101;&#114;&#x65;&#100;&#x2e;&#x69;&#x6f;">&#x6f;&#x6a;&#64;&#x62;&#117;&#102;&#102;&#101;&#x72;&#101;&#100;&#46;&#105;&#111;</a>').
-export([start/0, start_link/0, stop/0]).</p>

<p>ensure_started(App) -></p>

<pre><code>case application:start(App) of
    ok -&gt;
        ok;
    {error, {already_started, App}} -&gt;
        ok
end.
</code></pre>

<p>%% @spec start_link() -> {ok,Pid::pid()}
%% @doc Starts the app for inclusion in a supervisor tree
start_link() -></p>

<pre><code>ensure_started(crypto),
csd_core_sup:start_link().
</code></pre>

<p>%% @spec start() -> ok
%% @doc Start the csd_core server.
start() -></p>

<pre><code>ensure_started(crypto),
application:start(csd_core).
</code></pre>

<p>%% @spec stop() -> ok
%% @doc Stop the csd_core server.
stop() -></p>

<pre><code>Res = application:stop(csd_core),
application:stop(crypto),
Res.
</code></pre>

<p>{% endcodeblock %}</p>

<p>Next up, edit <code>csd_core.app.src</code> and add some application-specific information:</p>

<p>{% codeblock apps/csd_core/src/csd_core.app.src lang:erlang %}</p>

<p>{application, csd_core,
  [</p>

<pre><code>{description, "Core functionality for the Code Smackdown application."},
{vsn, "0.0.1"},
{registered, []},
{applications,
  [
    kernel,
    stdlib
  ]
},
{mod, {csd_core_app, []}},
{env, []}
</code></pre>

<p>  ]
}.
{% endcodeblock %}</p>

<p>We know that we'll be talking to Riak, so we need to make sure we've included the <code>riakc</code> (Riak client) dependency. Though I haven't yet talked about it, we'll also be using Mochiweb's <a href="https://github.com/mochi/mochiweb/blob/master/src/mochijson2.erl" title="Mochiweb's json module">mochijson2</a> module to help with handling JSON data, so we shall add this as a dependency to the application. Bear in mind this is already a dependency for the web component of the application, so we're not actually adding a <em>new</em> dependency to the overall application.</p>

<p>We can do this by creating a <code>rebar.config</code> in <code>apps/csd_core</code> and editing it to contain the following:</p>

<p>{% codeblock apps/csd_core/rebar.config lang:erlang %}
%%-<em>- mode: erlang -</em>-
{deps,
  [</p>

<pre><code>{mochiweb, "1.5.1", {git, "git://github.com/mochi/mochiweb", {tag, "1.5.1"}}},
{riakc, ".*", {git, "git://github.com/basho/riak-erlang-client", "HEAD"}}
</code></pre>

<p>  ]
}.
{% endcodeblock %}</p>

<p>Then we need to tell <code>rebar</code> to build this new application by adjusting the <code>rebar.config</code> in the <code>csd</code> root folder:</p>

<p>{% codeblock rebar.config lang:erlang %}
%%-<em>- mode: erlang -</em>-
{sub_dirs, ["apps/csd_core", "apps/csd_web"]}.
{% endcodeblock %}</p>

<p>Now we have enough to get the <code>csd_core</code> application started, even though it doesn't do anything. We just need to adjust our <code>Makefile</code> target so that it launches the <code>csd_core</code> application as well:</p>

<p>{% codeblock Makefile %}
ERL ?= erl
APP = csd</p>

<p>.PHONY: deps</p>

<p>all: deps
  @./rebar compile</p>

<p>app:
  @./rebar compile skip_deps=true</p>

<p>deps:
  @./rebar get-deps</p>

<p>clean:
  @./rebar clean</p>

<p>distclean: clean
  @./rebar delete-deps</p>

<p>webstart: app
  exec erl -pa $(PWD)/apps/*/ebin -pa $(PWD)/deps/*/ebin -boot start_sasl -s reloader -s csd_core -s csd_web</p>

<p>proxystart:
  @haproxy -f dev.haproxy.conf
{% endcodeblock %}</p>

<p>Then off we go:</p>

<pre><code>oj@spawn-link ~/blog/csd $ make webstart
==&gt; csd_core (compile)
Compiled src/csd_core_app.erl
Compiled src/csd_core_sup.erl
Compiled src/csd_core.erl

   ... snip ...

=PROGRESS REPORT==== 4-Apr-2011::21:49:27 ===
         application: csd_core
          started_at: nonode@nohost

   ... snip ...

=PROGRESS REPORT==== 4-Apr-2011::21:49:27 ===
         application: csd_web
          started_at: nonode@nohost
</code></pre>

<p>As you can see we now have a system which contains both <code>csd_core</code> and <code>csd_web</code>. This is great, but <code>csd_core</code> needs a lot more work. The intent for this application is to be an <a href="http://en.wikipedia.org/wiki/Open_Telecom_Platform" title="Open Telecom Platform">OTP</a> application which provides an API to the <code>csd</code> logic and back-end database. This means we're going to need to get ourselves a <a href="http://www.erlang.org/doc/design_principles/gen_server_concepts.html" title="gen_server behaviour">gen_server</a> set up which can handle requests from various clients. Let's do that next.</p>

<p>Thankfully <code>rebar</code> comes with a simple template that we can use for creating the <code>gen_server</code> behaviour, so we can invoke that from the command line and have it generate the shell for us:</p>

<pre><code>oj@spawn-link ~/blog/csd/apps/csd_core $ ../../rebar create template=simplesrv srvid=csd_core_server
==&gt; csd_core (create)
Writing src/csd_core_server.erl
</code></pre>

<p>We now have a very dumb server ready to go, to make it start with the rest of the application we have to modify <code>csd_core_sup</code>, the <a href="http://www.erlang.org/doc/design_principles/sup_princ.html" title="supervisor behaviour">supervisor</a> and tell it to fire up the server for us:</p>

<p>{% codeblock apps/csd_core/src/csd_core_sup.erl lang:erlang %}
-module(csd_core_sup).</p>

<p>-behaviour(supervisor).</p>

<p>%% API
-export([start_link/0]).</p>

<p>%% Supervisor callbacks
-export([init/1]).</p>

<p>%% Helper macro for declaring children of supervisor
-define(CHILD(I, Type), {I, {I, start_link, []}, permanent, 5000, Type, [I]}).</p>

<p>%% ===================================================================
%% API functions
%% ===================================================================</p>

<p>start_link() ->
  supervisor:start_link({local, ?MODULE}, ?MODULE, []).</p>

<p>%% ===================================================================
%% Supervisor callbacks
%% ===================================================================</p>

<p>init([]) ->
  Server = ?CHILD(csd_core_server, worker),
  Processes = [Server],
  {ok, { {one_for_one, 5, 10}, Processes} }.
{% endcodeblock %}</p>

<p>With this in place we can now start our application again and we should see the new <code>csd_core_server</code> appear in the start-up sequence:</p>

<pre><code>oj@spawn-link ~/blog/csd $ make webstart

   ... snip ...

=PROGRESS REPORT==== 4-Apr-2011::22:04:04 ===
          supervisor: {local,csd_core_sup}
             started: [{pid,&lt;0.54.0&gt;},
                       {name,csd_core_server},
                       {mfargs,{csd_core_server,start_link,[]}},
                       {restart_type,permanent},
                       {shutdown,5000},
                       {child_type,worker}]

=PROGRESS REPORT==== 4-Apr-2011::22:04:04 ===
         application: csd_core
          started_at: nonode@nohost

   ... snip ...
</code></pre>

<p>The shell and structure of our application is now in place. We are finally ready to start talking to Riak!</p>

<p>Again, now is the time to have a mini-break if you need one. Grab a <em>Shigar und a waffle</em> and a cup of English Breakfast tea.</p>

<h2>Preparing csd_core for Riak connectivity</h2>

<p>Given that this is the first look at connecting to Riak, we're going to have to set up a little infrastructure to support our needs. As a result, the data itself won't be discussed much for fear of turning this post into something way more epic than originally intended.</p>

<p>So in short, we're interested in storing the idea of a <em>code snippet</em>. That is an entity which contains two opposing blobs of code which are being compared. That snippet will have a title. Down the track, more information will be associated with this snippet, such as the author, along with links to a set of comments and votes. For now we'll just focus on storing the bare essentials of the snippet.</p>

<h3>The Snippet</h3>

<p>As far as our Erlang code is concerned, our snippet is going to be a simple list of properties that we can interact with via the <a href="http://www.erlang.org/doc/man/proplists.html" title="proplists">proplists</a> module. This keeps things really simple. To demonstrate what our snippet will look like in code, here is the function that takes a Title, and the two code blobs (called Left and Right) and returns a <code>snippet</code> instance. This code goes in a module called <code>csd_snippet</code> defined in <code>src/csd_snippet.erl</code>:</p>

<p>{% codeblock apps/csd_core/src/csd_snippet.erl (part) lang:erlang %}
to_snippet(Title, Left, Right) ->
  {snippet,</p>

<pre><code>[
  {title, Title},
  {left, Left},
  {right, Right}
]
</code></pre>

<p>  }.
{% endcodeblock %}</p>

<p>Note that the first part of the tuple is the atom <code>snippet</code> which I am using to identify the layout of the contents in the second part of the tuple. Down the track we'll have more collections of data in the system than just snippets, and we may want to make sure that the caller doesn't accidentally pass in a <code>user</code>, for example, to a function expecting a <code>snippet</code>.</p>

<p>It is important at this point to note that, down the track, I will include a <code>key</code> property in all of the data objects that are pushed to Riak. This property serves as the identifier for the object in Riak and is stored alongside the rest of the data so that it is easy to relate the in-memory instance back to the stored instance. This value, if not specified, will be inserted automatically when an item is saved via the API functions in <code>csd_core</code>. More on this later.</p>

<h3>Formatting Data for Storage in Riak</h3>

<p>Riak is very flexible in that it will store whatever kind of information you give it. This is good because it means we can cater our data format to whatever needs we have.</p>

<p>In our case, the <em>easiest</em> option would be to store our Erlang terms as binary using <a href="http://www.erlang.org/doc/man/erlang.html#term_to_binary-1" title="term_to_binary">term_to_binary</a> as we wouldn't have to think about <em>anything</em> else. We could easily read the data using <a href="http://www.erlang.org/doc/man/erlang.html#binary_to_term-1" title="binary_to_term">binary_to_term</a>. Done.</p>

<p>This comes with a set of problems though. For example, if we wanted to <a href="http://en.wikipedia.org/wiki/MapReduce" title="map/reduce">map/reduce</a> using JavaScript we wouldn't find it easy to get the data into a format that we could use. Another example would be that the RESTful interface to Riak would be close to useless because <strong>any</strong> non-Erlang client would have to somehow get the data into a meaningful format to work with.</p>

<p>Instead of using binary and throwing Erlang terms straight into Riak, we're going to use <a href="http://json.org/" title="JavaScript Object Notation">JSON</a>. It's very easy to convert to and from JSON in many different languages, and it's very easy to read. We can also easily verify that the data is being stored correctly by querying Riak's RESTful interface directly using <a href="http://curl.haxx.se/" title="cURL homepage">cURL</a> or a browser.</p>

<p>In order to store data in JSON format, we're going to enlist the help of <a href="https://github.com/mochi/mochiweb/blob/master/src/mochijson2.erl" title="Mochiweb's json module">mochijson2</a>, a library that comes with <a href="https://github.com/mochi/mochiweb" title="Mochiweb">Mochiweb</a> that makes it a <em>lot</em> easier to deal with JSON than doing everything manually. Given that we're using Webmachine for the front-end (which itself relies on Mochiweb) we already have the dependency available.</p>

<p>Unfortunately we can't just throw our data straight at this module and have it do everything for us. <code>mochijson2</code> requires data to be in a certain format before it can encode it to JSON. When decoding <em>from</em> JSON, it converts the data into the same format. Hence, we need the ability to convert our own data format to and from this intermediate data format so that <code>mochijson2</code> can deal with it.</p>

<p>We need two functions: <code>to_json()</code> and <code>from_json()</code>, and we shall define these in a helper module called <code>csd_json</code>. This module will live in <code>csd_core</code>:</p>

<p>{% codeblock apps/csd_core/src/csd_json.erl (part) lang:erlang %}
-module(csd_json).
-export([from_json/1, from_json/2, to_json/1, to_json/2]).</p>

<p>to_json(PropList) ->
  to_json(PropList, fun(_) -> true end).</p>

<p>to_json(PropList, IsStrFun) ->
  list_to_binary(mochijson2:encode(from_proplist(PropList, IsStrFun))).</p>

<p>from_json(Json) ->
  from_json(Json, fun(_) -> true end).</p>

<p>from_json(Json, IsStrFun) ->
  to_proplist(mochijson2:decode(Json), IsStrFun).
{% endcodeblock %}</p>

<p>You're probably wondering why each of these functions requires the <code>IsStrFun</code> parameter (if you're not, you're obviously an experienced Erlanger!). For those who don't know, strings in Erlang are actually lists of integers. This is fantastic as it makes it easy to manipulate strings as if they were lists, but it comes at a small price: it's not possible to determine the difference between a list of integers and a string.</p>

<p>Why is this important? <code>mochijson2</code> needs strings to be encoded as binaries, so we need a way to differentiate between integer lists and real strings. My original implementations of both the <code>to_json()</code> and <code>from_json()</code> functions attempted to figure out if certain fields were strings or not by looking at the content of the list. Not only was the code messy, but it wasn't foolproof. Instead, I made the decision to force the user to provide a callback function which will tell the JSON serialiser if the given property is a string or not. This callback takes a single parameter which is the name (in atom form) of the property and returns a boolean -- <code>true</code> indicates that the value is a string, <code>false</code> otherwise.</p>

<p>In some cases we might just be happy to encode/decode every single value as a string. Hence, there is an overload to both <code>to_json()</code> and <code>from_json()</code> which caters for this case. The rest of the code which implments the conversion is listed below. Don't feel that you need to understand the code below, as it's really not the goal of this post. The full source to this module is included in the source link specified at the end of this post.</p>

<p>{% codeblock apps/csd_core/src/csd_json.erl (part) lang:erlang %}
from_proplist(List=[H|<em>], IsStrFun) when is_tuple(H) ->
  { struct, lists:map(fun(P) -> from_proplist(P, IsStrFun) end, List) };
from_proplist({PropName, ComplexProp=[H|</em>]}, IsStrFun) when is_tuple(H) ->
  { list_to_binary(atom_to_list(PropName)), from_proplist(ComplexProp, IsStrFun) };
from_proplist({PropName, PropVal}, IsStrFun) ->
  { list_to_binary(atom_to_list(PropName)), to_value(PropName, PropVal, IsStrFun) }.</p>

<p>to_proplist({struct, PropList}, IsStrFun) when is_list(PropList) ->
  lists:map(fun(P) -> to_proplist(P, IsStrFun) end, PropList);
to_proplist({PropName, ComplexProp={struct, _}}, IsStrFun) ->
  { list_to_atom(binary_to_list(PropName)), to_proplist(ComplexProp, IsStrFun) };
to_proplist({PropName, PropVal}, IsStrFun) ->
  PropAtom = list_to_atom(binary_to_list(PropName)),
  { PropAtom, from_value(PropAtom, PropVal, IsStrFun) }.</p>

<p>to_value(PropName, L=[H|_], IsStrFun) when is_list(L) and is_list(H) ->
  lists:map(fun(P) -> to_value(PropName, P, IsStrFun) end, L);
to_value(PropName, L, IsStrFun) when is_list(L) ->
  case IsStrFun(PropName) of</p>

<pre><code>true -&gt; list_to_binary(L);
_ -&gt; lists:map(fun(V) -&gt; to_value(PropName, V, IsStrFun) end, L)
</code></pre>

<p>  end;
to_value(<em>, V, </em>) ->
  V.</p>

<p>from_value(PropName, L, IsStrFun) when is_list(L) ->
  lists:map(fun(P) -> from_value(PropName, P, IsStrFun) end, L);
from_value(PropName, B, IsStrFun) when is_binary(B) ->
  case IsStrFun(PropName) of</p>

<pre><code>true -&gt; binary_to_list(B);
_ -&gt; B
</code></pre>

<p>  end;
from_value(<em>, V, </em>) ->
  V.
{% endcodeblock %}</p>

<p>We are now able to read and write data to and from JSON format. Now we need to use the Riak client to push that into our Riak cluster.</p>

<h3>Setting up the Riak client</h3>

<p>Basho have done a great job of creating a protocol buffer-based client for use with Riak. The interface is really simple to use. Despite that, we shall create a module which will deal with this for us. This gives us a single point of abstraction of Riak and a place where we can add extra support for our own needs without spreading Riak-specific code all over the source base.</p>

<p>The first problem we need to resolve is: <em>what do we do with configuration?</em></p>

<p>This was a question I initially didn't know how to answer. After a bit of deliberation and a chat with a <a href="http://twitter.com/mononcqc" title="Ferd T-H on Twitter">respected Erlang sifu</a> (who has a <a href="http://learnyousomeerlang.com/" title="Learng you some erlang">fantastic Erlang tutorial site</a>) I decided to go with a module-based option.</p>

<p>We have our Riak cluster hidden behind the <code>haproxy</code> load balancer, and hence we have a single entry-point to connect to. If this entry-point changes, it changes for all of the clients, not just a single client. Therefore, I want the ability to manage a single set of connection information, but I want the ability to update it on the fly without having to restart the <code>csd_core</code> application. This is Erlang, after all, and modifying code and configuration on-the-fly is extremely easy. We shall abuse that.</p>

<p>We create a single module, <code>csd_riak_config.erl</code>, to contain our configuration which is referenced at start-up. It looks like this:</p>

<p>{% codeblock apps/csd_core/src/csd_riak_config.erl lang:erlang %}
-module(csd_riak_config).
-export([connection_info/0]).</p>

<p>connection_info() ->
  { "127.0.0.1", 8080 }.
{% endcodeblock %}</p>

<p>Pretty simple stuff. Let's use this functionality in our <code>gen_server</code>, and carry the configuration through from initialisation to all of the calls that will be made to the Riak server. This requires two simple modifications to the <code>csd_core_server</code> module:</p>

<p>{% codeblock apps/csd_core/src/csd_core_server.erl (part) lang:erlang %}
start_link() ->
  ConnInfo = csd_riak_config:connection_info(),
  gen_server:start_link({local, ?SERVER}, ?MODULE, [ConnInfo], []).</p>

<p>% ...</p>

<p>init([ConnInfo]) ->
  {ok, ConnInfo}.
{% endcodeblock %}</p>

<p>Confiuration is now loaded and is being passed to all of our <code>gen_server</code> callbacks. Let's make use of it. <code>csd_snippet</code> is the entry point for all snippet-related information, and one of the things that we are going to want to be able to do is write a snippet to Riak. So let's create a code-path that can do that.</p>

<h4>Writing Data to Riak</h4>

<p>The first point of call for a client is the OTP interface. Let's create an API call and a call handler to support saving snippets in <code>csd_core_server</code>:</p>

<p>{% codeblock apps/csd_core/src/csd_core_server.erl (part) lang:erlang %}</p>

<p>%% This is a simple function which invokes a call via the gen_sever
%% behaviour.
save_snippet(Snippet) ->
  gen_server:call(?SERVER, {save_snippet, Snippet}, infinity).</p>

<p>%% Handle the case where a caller wants to save a snippet to Riak. We
%% create a connection to Riak and pass that into the snippet handler
%% along with the snippet that needs to be saved. We return the newly
%% saved snippet.
handle_call({save_snippet, Snippet}, _From, ConnInfo) ->
  RiakPid = csd_riak:connect(ConnInfo),
  SavedSnippet = csd_snippet:save(RiakPid, Snippet),
  {reply, SavedSnippet, ConnInfo};
{% endcodeblock %}</p>

<p>Of course, we will need to export the <code>save_snippet()</code> function if we want to be able to call it.</p>

<p>You'll notice that we're getting the connection information passed in as the state for the OTP call, and that we're using that to create a connection to Riak via the <code>csd_riak</code> module. We shall cover this module in just a minute, but hopefully the interface to this function should make it relatively self-explanatory.</p>

<p>You might be wondering "Why are you creating the Riak client connection here instead of letting the <code>csd_snippet:save()</code> function do it by itself. It's a good question. The reason I decided to create the connection as part of OTP call rather than in the data/helper modules is because down the track there will probably be a need to do multiple interactions with Riak in a single call. If we force each of the called modules, such as <code>csd_snippet</code>, to establish their own connections then we'd probably have <em>multiple connections to Riak being created during a single client request</em>. This isn't what I would like to see happen, so it made sense (in my view) to create the client connection once and reuse it across all modules that are invoked during the request.</p>

<p>With that out of the way, we need to implement the <code>save()</code> function in the <code>csd_snippet</code> module. Brace yourself:</p>

<p><span class="filename"></span>
{% codeblock apps/csd_core/src/csd_snippet.erl (part) lang:erlang %}
save(RiakPid, Snippet={snippet, SnippetData}) ->
  case proplists:get_value(key, SnippetData, undefined) of</p>

<pre><code>undefined -&gt;
  Key = csd_riak:new_key(),
  NewSnippetData = [{key, Key} | SnippetData],
  RiakObj = csd_riak:create(?BUCKET, Key, to_json_internal(NewSnippetData)),
  ok = csd_riak:save(RiakPid, RiakObj),
  {snippet, NewSnippetData};
ExistingKey -&gt;
  RiakObj = csd_riak:fetch(RiakPid, ?BUCKET, ExistingKey),
  NewRiakObj = csd_riak:update(RiakObj, to_json_internal(SnippetData)),
  ok = csd_riak:save(RiakPid, NewRiakObj),
  Snippet
</code></pre>

<p>  end.
{% endcodeblock %}</p>

<p>On the surface this looks a little complicated, but it's actually very simple. As mentioned earlier in the post, we use a <code>key</code> property to store the identifier of the object in Riak. This code supports this notion. It works as follows:</p>

<ol>
<li><strong>Try to get the value of the <code>key</code> from the given list of properties.</strong></li>
<li><strong>If <em>not</em> found ...</strong>

<ol>
<li>create a new key using the <code>new_key()</code> function in the <code>csd_riak</code> module (this will be covered shortly).</li>
<li>Add the <code>key</code> to the list of properties for the snippet.</li>
<li>Create a new instance of a Riak object (more on this later) which contains the details of the snippet data to be written, along with the target bucket name and the key of the snippet.</li>
<li>Save the Riak object to the Riak cluster using the specified Riak client connection (Pid), and for now assume that it succeeds.</li>
<li>Return the new set of snippet data with the snippet's key included.</li>
</ol>
</li>
<li><strong>If found ...</strong>

<ol>
<li>Load the existing data from the Riak cluster into a Riak object.</li>
<li>Update the Riak object with the new data values passed into the function.</li>
<li>Save the Riak object <em>back</em> to the Riak cluster using the specified Riak client connection (Pid), and for now assume that it succeeds.</li>
<li>Return the snippet back to the caller as is.</li>
</ol>
</li>
</ol>


<p>It's fairly basic functionality which does enough to cater for our needs at this point. Through this one function, we can write new snippet instances to Riak, and we can update them too.</p>

<p>You'll also notice that another function is being called that hasn't been discussed: <code>to_snippet_internal()</code>. Rather than try to explain this, let's see the code as it's quite easy to follow:</p>

<p>{% codeblock apps/csd_core/src/csd_snippet.erl (part) lang:erlang %}
%% exported functions
to_json({snippet, SnippetData}) ->
  to_json_internal(SnippetData).</p>

<p>from_json(SnippetJson) ->
  from_json_internal(SnippetJson).</p>

<p>%% helper functions used internally.
to_json_internal(SnippetData) ->
  csd_json:to_json(SnippetData, fun is_string/1).</p>

<p>from_json_internal(SnippetJson) ->
  {snippet, csd_json:from_json(SnippetJson, fun is_string/1)}.</p>

<p>is_string(title) -> true;
is_string(left) -> true;
is_string(right) -> true;
is_string(_) -> false.
{% endcodeblock %}</p>

<p>As you can see, these are helper functions which call the <code>csd_json</code> functions to serialise/deserialise to/from JSON format. The <code>is_string()</code> function is the one that is used to tell the JSON functionality which properties are strings and which are not. At the moment, all properties defined on the snippet are string properties. Bear in mind that the <code>key</code> property, which is added automatically, is <em>not</em> a string.</p>

<p>All that is left is to see how <code>csd_riak</code> deals with the underlying Riak connectivity. Prepare to be underwhelmed!</p>

<p>{% codeblock apps/csd_core/src/csd_riak.erl lang:erlang %}
%% @spec connect(connection_info()) -> pid()
%% @doc Create a connection to the specified Riak cluster and
%%      return the Pid associated with the new connection.
connect({IP, Port}) ->
  {ok, RiakPid} = riakc_pb_socket:start_link(IP, Port),
  RiakPid.</p>

<p>%% @spec create(binary, binary, json) -> riakc_obj()
%% @doc Create a new instance of a riak object using the
%%      parameters given. The riak object can then be
%%      persisted to a Riak node/cluster. This overload
%%      assumes that the data passed in is JSON and sets
%%      the MIME type to "application/json" for you.
create(Bucket, Key, JsonData) ->
  create(Bucket, Key, JsonData, "application/json").</p>

<p>%% @spec create(binary, binary, term(), string) -> riakc_obj()
%% @doc Create a new instance of a riak object using the
%%      parameters given. The riak object can then be
%%      persisted to a Riak node/cluster. This overload
%%      takes arbitrary data and requires the user to
%%      specify the mime type of the data that is being
%%      stored.
create(Bucket, Key, Item, MimeType) ->
  RiakObj = riakc_obj:new(Bucket, Key, Item, MimeType),
  RiakObj.</p>

<p>%% @spec fetch(pid(), binary, binary) -> riakc_obj()
%% @doc Fetches a riakc object from a Riak node/cluster
%%      using the connection given.
fetch(RiakPid, Bucket, Key) ->
  RiakObj = riakc_pb_socket:get(RiakPid, Bucket, Key),
  RiakObj.</p>

<p>%% @spec update(riakc_obj(), term()) -> riakc_obj()
%% @doc Updates the stored value for a riakc object with
%%      the new one specified.
update(RiakObj, NewValue) ->
  NewRiakObj = riakc_obj:update_value(RiakObj, NewValue),
  NewRiakObj.</p>

<p>%% @spec get_value(riakc_obj()) -> term()
%% @doc Retrieves the stored value from within the riakc
%%      object.
get_value(RiakObj) ->
  Value = riakc_obj:get_value(RiakObj),
  Value.</p>

<p>%% @spec save(pid(), riakc_obj()) -> {ok, riakc_obj()} | {error | Reason}
%% @doc Saves the given riak object to the specified Riak node/cluster.
save(RiakPid, RiakObj) ->
  Result = riakc_pb_socket:put(RiakPid, RiakObj),
  Result.</p>

<p>%% @spec new_key() -> key()
%% @doc Generate an close-to-unique key that can be used to identify
%%      an object in riak. This implementation is blatantly borrowed
%%      (purloined) from the wriaki source (thanks basho!)
new_key() ->
  { {Yr, Mo, Dy}, {Hr, Mn, Sc} } = erlang:universaltime(),
  {<em>, </em>, Now} = now(),
  new_key([Yr, Mo, Dy, Hr, Mn, Sc, node(), Now]).</p>

<p>%% @spec new_key(list()) -> key()
%% @doc Generate an close-to-unique key that can be used to identify
%%      an object in riak using the given list parameter as the stuff
%%      to hash.
new_key(List) ->
  Hash = erlang:phash2(List),
  base64:encode(&lt;&lt;Hash:32>>).
{% endcodeblock %}</p>

<p>Hopefully the code in this module is fairly self-explanatory. It's a very simple API to follow which made it very easy to build. So with this in place, let's fire up the application, create a new snippet and see if it lands in the Riak store:</p>

<pre><code>oj@spawn-link  ~/blog/csd $ make webstart

   ... snip ...

=PROGRESS REPORT==== 4-Apr-2011::22:54:55 ===
         application: csd_web
          started_at: nonode@nohost

1&gt; Snippet = csd_snippet:to_snippet(
1&gt; "Super composition!",
1&gt; "(.^) = (.) . (.)",
1&gt; "(.^) = fmap `fmap` fmap").
{snippet,[{title,"Super composition!"},
          {left,"(.^) = (.) . (.)"},
          {right,"(.^) = fmap `fmap` fmap"}]}
2&gt; SavedSnippet = csd_core_server:save_snippet(Snippet).

PROGRESS REPORT==== 4-Apr-2011::22:57:13 ===
          supervisor: {local,inet_gethost_native_sup}
             started: [{pid,&lt;0.103.0&gt;},{mfa,{inet_gethost_native,init,[[]]}}]

=PROGRESS REPORT==== 4-Apr-2011::22:57:13 ===
          supervisor: {local,kernel_safe_sup}
             started: [{pid,&lt;0.102.0&gt;},
                       {name,inet_gethost_native_sup},
                       {mfargs,{inet_gethost_native,start_link,[]}},
                       {restart_type,temporary},
                       {shutdown,1000},
                       {child_type,worker}]
{snippet,[{key,&lt;&lt;"B41kUQ=="&gt;&gt;},
          {title,"Super composition!"},
          {left,"(.^) = (.) . (.)"},
          {right,"(.^) = fmap `fmap` fmap"}]}
</code></pre>

<p>As you can see from the above script dump, a new <code>key</code> was generated for us and stored alongside the snippet (it's highlighted in bold). Verifying that the data has persisted is simple. We can hit any of the Riak nodes via its web interface. Let's take a look at <strong>http://localhost:8091/riak/snippet/B41kUQ==</strong> (your URL will have a different key):</p>

<p><img src="http://buffered.io/uploads/2010/10/localhost-verify-write.png" /></p>

<p>Great stuff! For more detail, let's see what cURL has to say:</p>

<pre><code>oj@spawn-link ~/blog/csd/ $ curl http://localhost:8091/riak/snippet/B41kUQ== -v
* About to connect() to localhost port 8091 (#0)
*   Trying ::1... Connection refused
*   Trying 127.0.0.1... connected
* Connected to localhost (127.0.0.1) port 8091 (#0)
&gt; GET /riak/snippet/B41kUQ== HTTP/1.1
&gt; User-Agent: curl/7.21.0 (x86_64-pc-linux-gnu) libcurl/7.21.0 OpenSSL/0.9.8o zlib/1.2.3.4 libidn/1.18
&gt; Host: localhost:8091
&gt; Accept: */*
&gt; 
&lt; HTTP/1.1 200 OK
&lt; X-Riak-Vclock: a85hYGBgzGDKBVIsjOy7jmcwJTLmsTJ8tuc7zpcFAA==
&lt; Vary: Accept-Encoding
&lt; Server: MochiWeb/1.1 WebMachine/1.7.3 (participate in the frantic)
&lt; Link: &lt;/riak/snippet&gt;; rel="up"
&lt; Last-Modified: Mon, 04 Apr 2011 13:13:23 GMT
&lt; ETag: "6fw7c5v4IPAsf4B5hMHybc"
&lt; Date: Mon, 04 Apr 2011 13:13:36 GMT
&lt; Content-Type: application/json
&lt; Content-Length: 107
&lt; 
* Connection #0 to host localhost left intact
* Closing connection #0
{"key":"B41kUQ==","title":"Super composition!","left":"(.^) = (.) . (.)","right":"(.^) = fmap `fmap` fmap"}
</code></pre>

<p>As you can see, it has not only serialised to JSON properly, but the MIME type has been set correctly as well.</p>

<p>This is all well and good, but we need our code to be able to read from Riak as well. That's up next.</p>

<h4>Reading Data from Riak</h4>

<p>We've already covered off what happens at the bottom level when reading data from Riak (see the above code snippet for more info). To enable this functionality at the top level, we simply need to create a <code>gen_server</code> call, handle it appropriately and expose a function in the <code>csd_snippet</code> module. Let's start at the top level:</p>

<p>{% codeblock - apps/csd_core/src/csd_core_server.erl (part) lang:erlang %}
%% OTP API function to get a snippet based on the key
get_snippet(SnippetKey) ->
  gen_server:call(?SERVER, {get_snippet, SnippetKey}, infinity).</p>

<p>%% handle the call and call the functionality from csd_snippet
handle_call({get_snippet, SnippetKey}, _From, ConnInfo) ->
  RiakPid = csd_riak:connect(ConnInfo),
  Snippet = csd_snippet:fetch(RiakPid, SnippetKey),
  {reply, Snippet, ConnInfo};
{% endcodeblock %}</p>

<p>This code is a bit of a no-brainer. It's very similar to the writing code, but just a bit simpler. Let's see what the <code>csd_snippet:fetch()</code> function looks like:</p>

<p>{% codeblock apps/csd_core/src/csd_snippet.erl (part) lang:erlang %}
fetch(RiakPid, Key) ->
  {ok, RiakObj} = csd_riak:fetch(RiakPid, ?BUCKET, Key),
  SnippetJson = csd_riak:get_value(RiakObj),
  from_json_internal(SnippetJson).
{% endcodeblock %}</p>

<p>This code just pulls a Riak object out of the back-end, extracts is value and deserialises it from JSON to our Erlang <code>proplist</code>. Very simple stuff.</p>

<p>We should be able to build this and, via the Erlang console, verify that it functions:</p>

<pre><code>3&gt; Reloading csd_core_server ... ok.
3&gt; csd_core_server:get_snippet(&lt;&lt;"B41kUQ=="&gt;&gt;).
{snippet,[{key,&lt;&lt;"B41kUQ=="&gt;&gt;},
          {title,"Super composition!"},
          {left,"(.^) = (.) . (.)"},
          {right,"(.^) = fmap `fmap` fmap"}]}
</code></pre>

<p>Works like a charm. Now, for the icing on the cake, let's get this rendering in a very simple template in our browser.</p>

<h3>End to End</h3>

<p>In order to gain access to our data in Riak from the web we need to create a new resource. This resource will respond to any URI of the form <code>/snippet/&lt;key&gt;</code>. We shall call this resource <code>csd_web_snippet_resource</code> and we'll be putting this in our web application. It looks like this:</p>

<p>{% codeblock apps/csd_web/src/csd_web_snippet_resource.erl lang:erlang %}
%% @author OJ Reeves <a href="&#x6d;&#97;&#x69;&#x6c;&#116;&#x6f;&#x3a;&#x6f;&#x6a;&#x40;&#98;&#x75;&#x66;&#102;&#101;&#114;&#x65;&#100;&#x2e;&#105;&#x6f;">&#x6f;&#106;&#64;&#x62;&#x75;&#102;&#102;&#x65;&#114;&#101;&#x64;&#46;&#105;&#111;</a>
%% @copyright 2010 OJ Reeves
%% @doc Webmachine resource that handles snippet-related actions</p>

<p>-module(csd_web_snippet_resource).
-author('OJ Reeves <a href="&#109;&#x61;&#x69;&#108;&#116;&#x6f;&#58;&#x6f;&#106;&#64;&#98;&#117;&#102;&#102;&#101;&#114;&#x65;&#x64;&#46;&#x69;&#x6f;">&#x6f;&#106;&#x40;&#98;&#117;&#x66;&#x66;&#x65;&#x72;&#101;&#x64;&#x2e;&#x69;&#x6f;</a>').</p>

<p>-export([init/1, to_html/2]).</p>

<p>-include_lib("webmachine/include/webmachine.hrl").</p>

<p>init([]) -> {ok, undefined}.</p>

<p>to_html(ReqData, State) ->
  PathInfo = wrq:path_info(ReqData),
  {ok, SnippetKey} = dict:find(key, PathInfo),
  {snippet, SnippetData} = csd_core_server:get_snippet(list_to_binary(SnippetKey)),
  {ok, Content} = snippet_dtl:render(SnippetData),
  {Content, ReqData, State}.
{% endcodeblock %}</p>

<p>As you can see, this code calls through to the <code>csd_core_server</code> to extract the data from the back-end. The value that is used as a key for the snippet is one that is pulled from the URI via Webmachine's <code>wrq:path_info()</code> function. This function extracts values from the URI based on the rules in <code>dispatch.conf</code> and provides a <a href="http://www.erlang.org/doc/man/dict.html" title="Erlang dict">dict</a> which can be used to lookup the values.</p>

<p>The code also uses a new ErlyDTL template called <code>snippet</code>. We'd best add that to the <code>templates</code> folder:</p>

<p>{% codeblock apps/csd_web/templates/snippet.dtl lang:html %}</p>

<!-- TODO : get the templating engine to stop ripping out the inline template code -->


<p><html>
  <body></p>

<pre><code>&lt;h1&gt;Snippet View&lt;/h1&gt;
&lt;h2&gt;{{ "{{ title "}} }}&lt;/h2&gt;
&lt;p&gt;Left: {{ "{{ left "}} }}&lt;/p&gt;
&lt;p&gt;Right: {{ "{{ right "}} }}&lt;/p&gt;
</code></pre>

<p>  </body>
</html>
{% endcodeblock %}</p>

<p>Finally, we just need to adjust <code>dispatch.conf</code> to include the new route handler so that our code gets called:</p>

<p>{% codeblock apps/csd_web/priv/dispatch.conf lang:erlang %}
%%-<em>- mode: erlang -</em>-
{[], csd_web_resource, []}.
{["snippet", key], csd_web_snippet_resource, []}.
{% endcodeblock %}</p>

<p>Note how <code>key</code> is specified alongside <code>"snippet"</code>. This means that the path following <code>snippet/</code> in the URI will be associated with the <code>key</code> atom in the <code>dict</code> generated by <code>wrq:path_info()</code>.</p>

<p>We're ready to rock. Rebuild, then hit the right URL, <strong>http://localhost/snippet/B41kUQ==</strong> (again, your key will be different), and you should get the following:</p>

<p><img src="http://buffered.io/uploads/2010/10/webmachine-to-riak.png" /></p>

<h2>Wrapping up</h2>

<p>Thanks for sticking with me! As you can see there is a little bit of ground-work required if you're interested in producing some form of structure that you can reuse all over your application, but the effort is definitely worth it. Now we have something in place which we can use to store arbitrarily complex <code>proplists</code> into Riak in JSON format, we have the ability to talk to Riak (read and write), and we have a proper application structure in place which we can build on.</p>

<p>Please note that the mechanism implemented in this post is quite simple and doesn't cover all cases that will be required before the application is complete. In future posts, this implementation will change to support more of those cases, such as dealing with concurrent updates, handling versions, etc.</p>

<p>Many thanks to those people who took the time out of their busy schedules to review my post before I shared it with the world. Those people shall remain nameless to protect them from any mistakes made in this post (which are solely my own).</p>

<p>As always, comments and feedback is welcomed and greatly appreciated. As are suggestions on improvements, pitfalls and blatant mistakes :)</p>

<p><strong>Note:</strong> The code for Part 3 (this post) can be found on <a href="https://github.com/OJ/csd/tree/Part3-20110405" title="Source code for Part 3">Github</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Webmachine, ErlyDTL and Riak - Part 2]]></title>
    <link href="http://buffered.io/posts/webmachine-erlydtl-and-riak-part-2/"/>
    <updated>2010-09-12T22:15:00+10:00</updated>
    <id>http://buffered.io/posts/webmachine-erlydtl-and-riak-part-2</id>
    <content type="html"><![CDATA[<p><img src="http://buffered.io/uploads/2010/09/riak-logo.png" alt="Riak Logo" style="float:left;padding-right:5px;padding-bottom:5px;"/>In <a href="/posts/webmachine-erlydtl-and-riak-part-1/" title="Wembachine, ErlyDTL and Riak - Part 1">Part 1</a> of the series we covered the basics of getting the development environment up and running. We also looked at how to get a really simple ErlyDTL template rendering. If you haven't yet gone through Part 1, I suggest you do that now. If you have, read on!</p>

<p>There are a few reasons this series is targeting this technology stack. One of them is <strong>uptime</strong>. We're aiming to build a site that stays up as much as possible. Given that, one of the things that I missed in the previous post was setting up a <a href="http://en.wikipedia.org/wiki/Load_balancing_(computing)" title="Load balancing">load balancer</a>. Hence this post will attempt to fill that gap.</p>

<!--more-->


<p>Any serious web-based application will have load-balancing in play somewhere. While not essential during development, it's handy to have a similar set up in the hope that it exposes you to some potential issues you might face when the application reaches production.</p>

<p>There are many high-quality load-balancing solutions out there to choose from. For this series, we shall be using <a href="http://haproxy.1wt.eu/" title="HAProxy">HAProxy</a>, which is a common choice amongst developers building scalable web applications. The rest of this post will cover how to set up HAProxy, verifying that the configuration is correct and confirming that it behaves appropriately when nodes in our cluster go down.</p>

<p>Please note the goal is to demonstrate how HAProxy <em>can</em> be configured. When deploying to your production environments please make sure the configuration matches your needs.</p>

<h3>HAProxy installation</h3>

<p>Let's start by pulling down the latest stable version of HAProxy's source, extracting it and building it. Here's a sample log of what you should expect:</p>

<pre><code>oj@nix ~/blog $ wget http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.14.tar.gz

  ... snip ...

oj@nix ~/blog $ tar -xzf haproxy-1.4.14.tar.gz 

  ... snip ...
</code></pre>

<p>At this point we've got the source and we're ready to make. HAProxy requires a parameter in order to build, and this parameter varies depending on your target system:</p>

<pre><code>oj@nix ~/blog $ cd haproxy-1.4.14
oj@nix ~/blog/haproxy-1.4.14 $ make

Due to too many reports of suboptimized setups, building without
specifying the target is no longer supported. Please specify the
target OS in the TARGET variable, in the following form:

   make TARGET=xxx

Please choose the target among the following supported list :

   linux26, linux24, linux24e, linux22, solaris
   freebsd, openbsd, cygwin, custom, generic

Use "generic" if you don't want any optimization, "custom" if you
want to precisely tweak every option, or choose the target which
matches your OS the most in order to gain the maximum performance
out of it. Please check the Makefile in case of doubts.
make: *** [all] Error 1
</code></pre>

<p>According to <a href="http://en.wikipedia.org/wiki/Uname" title="uname">uname</a>, I'm running Linux Kernel 2.6:</p>

<pre><code>oj@nix ~/blog/haproxy-1.4.14 $ uname -r
2.6.31-21-generic
</code></pre>

<p>As a result, I'll be passing in <strong>linux26</strong>. Make sure you specify the correct option depending on which system you are running. We'll be building it <em>and</em> installing it so that it can be called from anywhere:</p>

<pre><code>oj@nix ~/blog/haproxy-1.4.14 $ make TARGET=linux26

    ... snip ...

oj@nix ~/blog/haproxy-1.4.14 $ sudo make install

   ... snip ...
</code></pre>

<p>Simple! We now need to create a configuration for HAProxy which we can use during development. Not surprisingly, HAProxy can be run as a daemon, but it can also be invoked from the command line with a configuration passed as a parameter. For our development, we'll be executing from the command line as this will give us feedback/output on what's going on.</p>

<p>Let's create a file called <code>dev.haproxy.conf</code> inside our application directory so that it can be included in our source:</p>

<p>{% codeblock dev.haproxy.conf lang:bash %}</p>

<h1>start with the global settings which will</h1>

<h1>apply to all sections in the configuration.</h1>

<p>global
  # specify the maximum connections across the board
  maxconn 2048
  # enable debug output
  debug</p>

<h1>now set the default settings for each sub-section</h1>

<p>defaults
  # stick with http traffic
  mode http
  # set the number of times HAProxy should attempt to
  # connect to the target
  retries 3
  # specify the number of connections per front and
  # back end
  maxconn 1024
  # specify some timeouts (all in milliseconds)
  timeout connect 5000
  timeout client 50000
  timeout server 50000</p>

<h6>##### Webmachine Configuration</h6>

<h1>here is the first of the front-end sections.</h1>

<h1>this is where we specify our webmachine instances.</h1>

<h1>in our case we start with just one instance, but</h1>

<h1>we can add more later</h1>

<p>frontend webfarm
  # listen on port 80 across all network interfaces
  bind *:80
  # by default, point at our backend configuration
  # which lists our webmachine instances (this is
  # configured below in another section)
  default_backend webmachines</p>

<h1>this section indicates how the connectivity to</h1>

<h1>all the instances of webmachine should work.</h1>

<h1>Again, for dev there is only one instance, but</h1>

<h1>in production there would be more.</h1>

<p>backend webmachines
  # we'll specify a round-robin configuration in
  # case we add nodes down the track.
  balance roundrobin
  # enable the "X-Forware-For" header so that
  # we can see the client's IP in Webmachine,
  # not just the proxy's address
  option forwardfor
  # later down the track we'll be making the use
  # of cookies for various reasons. So we'll
  # enable support for this while we're here.
  cookie SERVERID insert nocache indirect
  # list the servers who are to be balanced
  # (just the one in the case of dev)
  server Webmachine1 127.0.0.1:8000</p>

<h6>##### Riak Configuration</h6>

<h1>We are yet to touch Riak so far, but given that</h1>

<h1>this post is going to cover the basics of</h1>

<h1>connectivity, we'll cover off the configuration</h1>

<h1>now so we don't have to do it later.</h1>

<p>frontend dbcluster
  # We'll be using protocol buffers to talk to
  # Riak, so we will change from the default mode
  # and use tcp instead
  mode tcp
  # we're only interested in allowing connections
  # from internal sources (so that we don't expose
  # ourselves to the web. so we shall only listen
  # on an internal interface on port 8080
  bind 127.0.0.1:8080
  # Default to the riak cluster configuration
  default_backend riaks</p>

<h1>Here is the magic bit which load balances across</h1>

<h1>our three instances of riak which are clustered</h1>

<h1>together</h1>

<p>backend riaks
  # again, make sure we specify tcp instead of
  # the default http mode
  mode tcp
  # use a standard round robin approach for load
  # balancing
  balance roundrobin
  # list the three servers as optional targets
  # for load balancing - these are what we set
  # up during Part 1. Add health-checking as
  # well so that when nodes go down, HAProxy
  # can remove them from the cluster
  server Riak1 127.0.0.1:8081 check
  server Riak2 127.0.0.1:8082 check
  server Riak3 127.0.0.1:8083 check
{% endcodeblock %}</p>

<p>In the configuration above the <code>backend riaks</code> section has three server nodes. Each one of them has the <code>check</code> option specified. This enables health-checking on the same address and port that the server instance is bound to. If you decided that you didn't want to do health-checking in this manner you easily enable health-checking over HTTP, as Riak has a built-in URI which can be used to validate the state of the node. Change the <code>backend riaks</code> section in the configuration to look like this:
{% codeblock lang:bash %}</p>

<h1>Here is the magic bit which load balances across</h1>

<h1>our three instances of riak which are clustered</h1>

<h1>together</h1>

<p>backend riaks
  # again, make sure we specify tcp instead of
  # the default http mode
  mode tcp
  # use a standard round robin approach for load
  # balancing
  balance roundrobin
  # enable HTTP health checking using the GET method
  # on the URI "/ping". This URI is part of Riak and
  # can be used to determine if the node is up.
  # We specify that we want to use the GET action, and
  # use the URI "/ping" - this is the RESTful health
  # check URI that comes as part of Riak.
  option httpchk GET /ping
  # list the three servers as optional targets
  # for load balancing - these are what we set
  # up during Part 1. Add health-checking as
  # well so that when nodes go down, HAProxy
  # can remove them from the cluster.</p>

<p>  # change the health-check address of the node to 127.0.0.0:8091
  # which is the REST interface for the first Riak node
  server Riak1 127.0.0.1:8081 check addr 127.0.0.1 port 8091</p>

<p>  # change the health-check address of the node to 127.0.0.0:8092
  # which is the REST interface for the second Riak node
  server Riak2 127.0.0.1:8082 check addr 127.0.0.1 port 8092</p>

<p>  # change the health-check address of the node to 127.0.0.0:8093
  # which is the REST interface for the third Riak node
  server Riak3 127.0.0.1:8083 check addr 127.0.0.1 port 8093
{% endcodeblock %}</p>

<p>To make sure this is functioning correctly, we need to open two consoles and change our working directory to our <code>csd</code> application (for those who have forgotten, <code>csd</code> is the application we're building - it was mentioned in <a href="/posts/webmachine-erlydtl-and-riak-part-1/" title="Wembachine, ErlyDTL and Riak - Part 1">Part 1</a>). In console 1:</p>

<pre><code>oj@nix ~/blog/csd $ sudo haproxy -f dev.haproxy.conf -d
Available polling systems :
     sepoll : pref=400,  test result OK
      epoll : pref=300,  test result OK
       poll : pref=200,  test result OK
     select : pref=150,  test result OK
Total: 4 (4 usable), will use sepoll.
Using sepoll() as the polling mechanism.
</code></pre>

<p>This indicates that HAProxy is up and running and waiting for connections. Let's get Webmachine fired up in console 2:</p>

<pre><code>oj@nix ~/blog/csd $ ./start.sh

    ... snip ...

=PROGRESS REPORT==== 4-Apr-2011::23:39:27 ===
         application: csd
          started_at: nonode@nohost
</code></pre>

<p>Now Webmachine is fired up with our application running. We should be able to hit our page, this time at <a href="http://localhost/" title="localhost">localhost</a>, and see exactly what we saw at the end of <a href="/posts/webmachine-erlydtl-and-riak-part-1/" title="Wembachine, ErlyDTL and Riak - Part 1">Part 1</a>.</p>

<p><img src="http://buffered.io/uploads/2010/09/haproxy-validation.png" /></p>

<h3>Verification of HAProxy configuration</h3>

<p>On the surface it appears that we haven't broken anything. We also need to make sure that any communication with Riak that we have down the track is also functioning. So let's validate that now.</p>

<p>First, we have to make sure that Riak is running. If you have followed <a href="/posts/webmachine-erlydtl-and-riak-part-1/" title="Wembachine, ErlyDTL and Riak - Part 1">Part 1</a> already and your Riak cluster is running then you're good to go. If not, please read <a href="/posts/webmachine-erlydtl-and-riak-part-1/" title="Wembachine, ErlyDTL and Riak - Part 1">Part 1</a> for information on how to install Riak and configure it to run as a cluster of 3 nodes.</p>

<p>Next, let's create 3 new connections and use the <a href="https://github.com/basho/riak-erlang-client/blob/master/src/riakc_pb_socket.erl#L181" title="riakc_pb_socket:get_server_info/1">get_server_info/1</a> function to find out which node we are connected to. To do this, we'll need to use an Erlang console which has all the Riak dependencies ready to go. It just so happens that when we fired up our Webmachine instance, we got an Erlang console for free. Simply hit the <code>enter</code> key and you'll be given a prompt. Notice that when we connect to Riak using the <a href="https://github.com/basho/riak-erlang-client/blob/master/src/riakc_pb_socket.erl#L97" title="riakc_pb_socket:start_link/2">start_link/2</a> function, we are passing in the IP address and port of the load-balanced cluster instead of one of the running Riak nodes:
{% codeblock lang:erlang %}
1> {ok, C1} = riakc_pb_socket:start_link("127.0.0.1", 8080).</p>

<p>=PROGRESS REPORT==== 4-Apr-2011::23:41:18 ===</p>

<pre><code>      supervisor: {local,inet_gethost_native_sup}
         started: [{pid,&lt;0.148.0&gt;},{mfa,{inet_gethost_native,init,[[]]}}]
</code></pre>

<p>=PROGRESS REPORT==== 4-Apr-2011::23:41:18 ===</p>

<pre><code>      supervisor: {local,kernel_safe_sup}
         started: [{pid,&lt;0.147.0&gt;},
                   {name,inet_gethost_native_sup},
                   {mfargs,{inet_gethost_native,start_link,[]}},
                   {restart_type,temporary},
                   {shutdown,1000},
                   {child_type,worker}]
</code></pre>

<p>{ok,&lt;0.146.0>}
2> riakc_pb_socket:get_server_info(C1).
{ok,[{node,&lt;&lt;"dev1@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>3> {ok, C2} = riakc_pb_socket:start_link("127.0.0.1", 8080).
{ok,&lt;0.151.0>}
4> riakc_pb_socket:get_server_info(C2).
{ok,[{node,&lt;&lt;"dev2@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>5> {ok, C3} = riakc_pb_socket:start_link("127.0.0.1", 8080).
{ok,&lt;0.154.0>}
6> riakc_pb_socket:get_server_info(C3).
{ok,[{node,&lt;&lt;"dev3@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>{% endcodeblock %}</p>

<p>So we can see that the load balancer has allocated three different connections, each to a different node in the cluster. This is a good sign. So let's kill off one of the nodes:</p>

<pre><code>oj@nix ~/blog/riak/dev $ dev2/bin/riak stop
ok
</code></pre>

<p>In a very short period of time, you should see output in the HAProxy console which looks something like this:</p>

<pre><code>[WARNING] 253/235636 (11824) : Server riaks/Riak2 is DOWN, reason: Layer4 connection problem, info: "Connection refused", check duration: 0ms.
</code></pre>

<p>The load balancer noticed that the node has died. Let's make sure it no longer attempts to allocate connections to <code>dev2</code>. Note that we call <a href="http://www.erlang.org/documentation/doc-5.2/doc/getting_started/getting_started.html" title="Getting started">f()</a> in our console before running the same script again, as this forces the shell to forget about any existing variable bindings:
{% codeblock lang:erlang %}
7> f().
ok
8> {ok, C1} = riakc_pb_socket:start_link("127.0.0.1", 8080).
{ok,&lt;0.1951.0>}
9> riakc_pb_socket:get_server_info(C1).
{ok,[{node,&lt;&lt;"dev1@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>10> {ok, C2} = riakc_pb_socket:start_link("127.0.0.1", 8080).
{ok,&lt;0.1954.0>}
11> riakc_pb_socket:get_server_info(C2).
{ok,[{node,&lt;&lt;"dev3@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>12> {ok, C3} = riakc_pb_socket:start_link("127.0.0.1", 8080).
{ok,&lt;0.1957.0>}
13> riakc_pb_socket:get_server_info(C3).
{ok,[{node,&lt;&lt;"dev1@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>{% endcodeblock %}</p>

<p>As we hoped, <code>dev2</code> is nowhere to be seen. Let's fire it up again:</p>

<pre><code>oj@nix ~/blog/riak/dev $ dev2/bin/riak start
</code></pre>

<p><strong>Note:</strong> It isn't necessary to tell the node to rejoin the cluster. This happens automatically. Thanks to Siculars (see comment thread) for pointing that out.</p>

<p>HAProxy's console will show you that it has re-established a connection to <code>dev2</code></p>

<pre><code>[WARNING] 253/235852 (11824) : Server riaks/Riak2 is UP, reason: Layer7 check passed, code: 200, info: "OK", check duration: 1ms.
</code></pre>

<p>As a final test, let's make sure we see that node get connections when we attempt to connect:
{% codeblock lang:erlang %}
14> f().
ok
15> {ok, C1} = riakc_pb_socket:start_link("127.0.0.1", 8080).
{ok,&lt;0.4203.0>}
16> riakc_pb_socket:get_server_info(C1).
{ok,[{node,&lt;&lt;"dev3@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>17> {ok, C2} = riakc_pb_socket:start_link("127.0.0.1", 8080).
{ok,&lt;0.4206.0>}
18> riakc_pb_socket:get_server_info(C2).
{ok,[{node,&lt;&lt;"dev1@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>19> {ok, C3} = riakc_pb_socket:start_link("127.0.0.1", 8080).
{ok,&lt;0.4209.0>}
20> riakc_pb_socket:get_server_info(C3).
{ok,[{node,&lt;&lt;"dev2@127.0.0.1">>},</p>

<pre><code> {server_version,&lt;&lt;"0.12.0"&gt;&gt;}]}
</code></pre>

<p>{% endcodeblock %}</p>

<h3>Wrapping up</h3>

<p>Excellent. Now that we've got our load-balancer set up in development, we're ready to dive into connecting to Riak from our <code>csd</code> application. That will be the topic for the next post in this series.</p>

<p>As always, comments and feedback are welcome and greatly appreciated. Suggestions on improvements and pointers on mistakes would be awesome. To anyone out there who has put HAProxy into production, we would love to hear your comments on your configuration!</p>

<p><strong>Note:</strong> The code for Part 2 (this post) can be found on <a href="https://github.com/OJ/csd/tree/Part2-20110403" title="Source Code for Part 2">Github</a>.</p>
]]></content>
  </entry>
  
</feed>
